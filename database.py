"""
Simple PostgreSQL database functions for HostBay Telegram Bot
Direct database connections with raw SQL queries for transparency and performance
"""

import os
import asyncio
import logging
import json
import psycopg2
import psycopg2.pool
from psycopg2.extras import RealDictCursor, RealDictRow
from typing import Optional, Dict, List, Any, Union, cast, Tuple
import time
import random
import threading
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime, timedelta
from payment_validation import validate_payment_simple, log_validation_config

# Simplified connection pool with hardening for Neon
_connection_pool = None
_pool_lock = threading.Lock()
_pool_recreation_count = 0
_last_pool_recreation = 0

# NEON HARDENING: Async health probe for automatic recovery
_health_probe_task = None
_health_probe_enabled = True
_database_healthy = True
_last_health_check = 0

# PHASE 1: Database Threading for 5000+ User Scalability
_db_executor = None

# Simplified: Single security gate
FINANCIAL_OPERATIONS_ENABLED = os.getenv('FINANCIAL_OPERATIONS_ENABLED', 'true').lower() == 'true'

# ARCHITECT REQUIREMENT 3: Strict DB mode for testing to raise exceptions instead of graceful degradation
TEST_STRICT_DB = os.getenv('TEST_STRICT_DB', 'false').lower() == 'true'

# Global variables for simplified security system
_security_constraints_verified = True  # Simplified: always verified
_allow_degraded_startup = True  # Simplified: always allow startup
_safe_mode_enabled = False  # Simplified: never in safe mode
_security_verification_cache_time = 0  # Simplified: no caching needed
_security_verification_cache_duration = 3600  # 1 hour (not used in simplified mode)

def get_db_executor():
    """Get or create database thread pool executor for non-blocking operations"""
    global _db_executor
    if _db_executor is None:
        _db_executor = ThreadPoolExecutor(
            max_workers=50,  # Increased for 20+ ops/sec target (was 20)
            thread_name_prefix="db_worker"
        )
        logger.info("‚úÖ Database ThreadPoolExecutor created (50 workers) for high-performance async operations")
    return _db_executor

# Simplified security functions for import compatibility

def verify_financial_operation_safety(*args, **kwargs) -> bool:
    """Simplified financial operation safety check (accepts any parameters for compatibility)"""
    return FINANCIAL_OPERATIONS_ENABLED

def ensure_financial_operations_allowed() -> bool:
    """Simplified function to check if financial operations are allowed"""
    if not FINANCIAL_OPERATIONS_ENABLED:
        logger.warning("‚ö†Ô∏è Financial operations are disabled by configuration")
        return False
    return True

def enable_safe_mode(reason: str):
    """Simplified safe mode enabler (no-op in simplified system)"""
    global _safe_mode_enabled
    _safe_mode_enabled = True
    logger.warning(f"‚ö†Ô∏è Safe mode enabled: {reason}")

def get_security_status() -> Dict[str, Any]:
    """Get simplified security status for compatibility"""
    return {
        'security_verified': True,
        'safe_mode_enabled': False,
        'financial_operations_allowed': FINANCIAL_OPERATIONS_ENABLED,
        'degraded_startup_allowed': True
    }

# Removed complex security functions - replaced with simple gate in credit_user_wallet()

async def probe_database_health():
    """NEON HARDENING: Lightweight async health probe for automatic recovery"""
    global _database_healthy, _last_health_check
    
    try:
        database_url = os.getenv('DATABASE_URL')
        if not database_url:
            return False
        
        # Quick connection test with minimal timeout
        import psycopg2
        conn = psycopg2.connect(
            database_url,
            connect_timeout=3,  # Very fast timeout for probe
            sslmode='prefer'    # NEON FIX: Prefer SSL but allow fallback for auto-suspend compatibility
        )
        
        try:
            with conn.cursor() as cursor:
                cursor.execute("SELECT 1")
                cursor.fetchone()
            
            _last_health_check = time.time()
            
            # If database was previously unhealthy and is now healthy, recreate pool
            if not _database_healthy:
                logger.info("‚úÖ NEON HARDENING: Database endpoint resumed - recreating connection pool")
                if recreate_connection_pool():
                    _database_healthy = True
                    return True
            
            _database_healthy = True
            return True
            
        finally:
            conn.close()
            
    except Exception as e:
        error_msg = str(e).lower()
        if _database_healthy and any(indicator in error_msg for indicator in ['connection refused', 'timeout', 'no route']):
            logger.debug(f"üîÑ NEON HARDENING: Database appears to be auto-suspended: {e}")
            _database_healthy = False
        return False

async def start_health_probe():
    """NEON HARDENING: Start background health probe task"""
    global _health_probe_task, _health_probe_enabled
    
    if not _health_probe_enabled or _health_probe_task is not None:
        return
    
    async def health_probe_loop():
        logger.info("‚úÖ NEON HARDENING: Starting background database health probe")
        
        while _health_probe_enabled:
            try:
                await probe_database_health()
                # Probe every 30 seconds when healthy, every 10 seconds when unhealthy
                probe_interval = 30 if _database_healthy else 10
                await asyncio.sleep(probe_interval)
                
            except asyncio.CancelledError:
                logger.info("üîÑ NEON HARDENING: Health probe cancelled")
                break
            except Exception as probe_error:
                logger.warning(f"‚ö†Ô∏è NEON HARDENING: Health probe error: {probe_error}")
                await asyncio.sleep(30)  # Wait longer on probe errors
    
    _health_probe_task = asyncio.create_task(health_probe_loop())
    logger.info("‚úÖ NEON HARDENING: Background health probe started")

async def stop_health_probe():
    """NEON HARDENING: Stop background health probe task"""
    global _health_probe_task, _health_probe_enabled
    
    _health_probe_enabled = False
    
    if _health_probe_task:
        _health_probe_task.cancel()
        try:
            await _health_probe_task
        except asyncio.CancelledError:
            pass
        _health_probe_task = None
        logger.info("üîÑ NEON HARDENING: Background health probe stopped")

async def run_db(func, *args, **kwargs):
    """Run database operation in thread pool to prevent event loop blocking"""
    loop = asyncio.get_event_loop()
    executor = get_db_executor()
    return await loop.run_in_executor(executor, func, *args, **kwargs)

# PHASE 1: Database threading infrastructure for high concurrency

logger = logging.getLogger(__name__)

def recreate_connection_pool():
    """NEON HARDENING: Recreate connection pool to recover from dead connections"""
    global _connection_pool, _pool_recreation_count, _last_pool_recreation
    
    current_time = time.time()
    
    # Rate limiting: Don't recreate pool more than once every 10 seconds
    if current_time - _last_pool_recreation < 10:
        logger.debug("üîÑ Pool recreation rate limited - skipping")
        return False
    
    with _pool_lock:
        try:
            # Close existing pool if it exists
            if _connection_pool is not None:
                try:
                    _connection_pool.closeall()
                    logger.info("üîÑ NEON HARDENING: Closed existing connection pool")
                except Exception as close_error:
                    logger.warning(f"‚ö†Ô∏è Error closing existing pool: {close_error}")
            
            database_url = os.getenv('DATABASE_URL')
            if not database_url:
                raise ValueError("DATABASE_URL environment variable not found")
            
            # Create new pool with same hardened settings
            _connection_pool = psycopg2.pool.ThreadedConnectionPool(
                minconn=5,        # Start smaller after recreation
                maxconn=100,      # Keep high max for performance
                dsn=database_url,
                cursor_factory=RealDictCursor,
                connect_timeout=5,      # NEON HARDENING: Fast failure detection
                keepalives_idle=600,    # NEON HARDENING: 10 minutes - detect auto-suspend faster
                keepalives_interval=30, # NEON HARDENING: 30 seconds - more aggressive probing
                keepalives_count=3,     # NEON HARDENING: 3 failed probes before marking dead
                sslmode='prefer'        # NEON FIX: Prefer SSL but allow fallback for auto-suspend compatibility
            )
            
            _pool_recreation_count += 1
            _last_pool_recreation = current_time
            logger.info(f"‚úÖ NEON HARDENING: Connection pool recreated (#{_pool_recreation_count}) - recovering from dead connections")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå NEON HARDENING: Failed to recreate connection pool: {e}")
            _connection_pool = None
            return False

def get_connection_pool():
    """Get or create simplified database connection pool with Neon hardening"""
    global _connection_pool
    if _connection_pool is None:
        try:
            database_url = os.getenv('DATABASE_URL')
            if not database_url:
                raise ValueError("DATABASE_URL environment variable not found")
            
            # PERFORMANCE OPTIMIZATION: Increased connection pool size for 20+ ops/sec target
            # Previous: minconn=5, maxconn=50 (4.8 ops/sec)
            # Optimized: Scale up to support 20+ operations/second sustained throughput
            _connection_pool = psycopg2.pool.ThreadedConnectionPool(
                minconn=10,       # Increased minimum connections for immediate availability
                maxconn=100,      # Doubled maximum connections for 20+ ops/sec target
                dsn=database_url,
                cursor_factory=RealDictCursor,
                connect_timeout=5,      # NEON HARDENING: Reduced timeout for fast failure detection
                keepalives_idle=600,    # NEON HARDENING: 10 minutes - detect auto-suspend faster
                keepalives_interval=30, # NEON HARDENING: 30 seconds - more aggressive probing
                keepalives_count=3,     # NEON HARDENING: 3 failed probes before marking dead
                sslmode='prefer'        # NEON FIX: Prefer SSL but allow fallback for auto-suspend compatibility
            )
            logger.info("‚úÖ NEON HARDENING: Connection pool created with fast failure detection (10-100 connections)")
        except Exception as e:
            logger.error(f"Failed to create connection pool: {e}")
            raise
    return _connection_pool

def with_database_timeout(operation_func, timeout_seconds=10, operation_name="database operation"):
    """NEON HARDENING: Thread-safe wrapper to prevent database operations from hanging indefinitely"""
    import threading
    import time
    
    result_container = {'result': None, 'exception': None, 'completed': False}
    
    def target():
        try:
            result_container['result'] = operation_func()
            result_container['completed'] = True
        except Exception as e:
            result_container['exception'] = e
            result_container['completed'] = True
    
    # Start operation in a separate thread
    thread = threading.Thread(target=target)
    thread.daemon = True
    thread.start()
    
    # Wait for completion with timeout
    thread.join(timeout_seconds)
    
    if not result_container['completed']:
        logger.error(f"üí• NEON HARDENING: {operation_name} timed out after {timeout_seconds}s - preventing application hang")
        logger.info("üè• FALLBACK: Preventing application hang due to database timeout")
        logger.info("   ‚îî‚îÄ Background health probe will attempt automatic recovery")
        raise TimeoutError(f"NEON HARDENING: {operation_name} timed out after {timeout_seconds}s")
    
    if result_container['exception']:
        raise result_container['exception']
        
    return result_container['result']

def test_connection_health(conn, timeout_seconds=3):
    """NEON HARDENING: Thread-safe connection health test with timeout"""
    
    def _health_check():
        try:
            # Alternative approach: Test connection without cursor complications  
            try:
                # Simple connection test that avoids cursor factory issues
                conn.execute("SELECT 1")
                return True, "Healthy"
            except AttributeError:
                # If conn.execute doesn't work, use basic cursor
                with conn.cursor() as cursor:
                    cursor.execute("SELECT 1")
                    result = cursor.fetchone()
                    # Handle both tuple and dict results
                    if result is None:
                        return False, "No result from health query"
                    if hasattr(result, '__getitem__'):
                        # Try both numeric and string access for compatibility
                        try:
                            check_val = result[0] if isinstance(result, (tuple, list)) else result.get(0, result.get('?column?', None))
                            if check_val == 1:
                                return True, "Healthy"
                        except (KeyError, IndexError, TypeError):
                            pass
                    return False, f"Unexpected result format: {type(result)} = {result}"
                
                return True, "Healthy"
        except Exception as e:
            # Debug: Log the exact exception details
            logger.warning(f"üîç Health check exception debug - Type: {type(e)}, Str: '{str(e)}', Repr: {repr(e)}")
            return False, f"Health check failed: {e}"
    
    try:
        return with_database_timeout(_health_check, timeout_seconds, "connection health check")
    except TimeoutError:
        return False, "Health check timed out - possible auto-suspend"
    except Exception as e:
        error_msg = str(e).lower()
        if any(indicator in error_msg for indicator in ['connection closed', 'server closed', 'ssl connection', 'timeout', 'broken pipe']):
            return False, f"Dead connection detected: {e}"
        return False, f"Health check failed: {e}"

def get_connection():
    """NEON HARDENING: Get database connection with enhanced health testing"""
    pool_retry_attempts = 3  # Retry pool connections before falling back
    
    for pool_attempt in range(pool_retry_attempts):
        try:
            pool = get_connection_pool()
            conn = pool.getconn()
            
            if conn:
                conn.autocommit = True
                
                # NEON HARDENING: Enhanced health check with timeout
                is_healthy, health_message = test_connection_health(conn, timeout_seconds=3)
                
                if is_healthy:
                    logger.debug(f"‚úÖ Pool connection {pool_attempt + 1}: {health_message}")
                    return conn
                else:
                    logger.warning(f"üîÑ Pool connection {pool_attempt + 1}/{pool_retry_attempts}: {health_message}")
                    return_connection(conn, is_broken=True)
                    
                    # Continue to next pool attempt instead of falling back immediately
                    if pool_attempt < pool_retry_attempts - 1:
                        # Small delay to allow pool to recover
                        time.sleep(0.1)
                        continue
                        
            # No connection available from pool on this attempt
            if pool_attempt < pool_retry_attempts - 1:
                logger.debug(f"Pool attempt {pool_attempt + 1}/{pool_retry_attempts}: No connection available, retrying...")
                time.sleep(0.1)
                continue
                
        except Exception as pool_error:
            logger.warning(f"Pool attempt {pool_attempt + 1}/{pool_retry_attempts} failed: {pool_error}")
            if pool_attempt < pool_retry_attempts - 1:
                continue
    
    # FALLBACK: Only after all pool attempts failed
    logger.warning(f"‚ö†Ô∏è NEON HARDENING: Connection pool exhausted after {pool_retry_attempts} attempts, using direct connection")
    
    try:
        database_url = os.getenv('DATABASE_URL')
        if not database_url:
            raise Exception("DATABASE_URL not configured")
            
        conn = psycopg2.connect(
            database_url,
            cursor_factory=RealDictCursor,
            connect_timeout=5,      # NEON HARDENING: Fast failure detection
            keepalives_idle=600,    # NEON HARDENING: 10 minutes - detect auto-suspend faster
            keepalives_interval=30, # NEON HARDENING: 30 seconds - more aggressive probing
            keepalives_count=3,     # NEON HARDENING: 3 failed probes before marking dead
            sslmode='prefer'        # NEON FIX: Prefer SSL but allow fallback for auto-suspend compatibility
        )
        conn.autocommit = True
        
        # Test the direct connection too
        is_healthy, health_message = test_connection_health(conn, timeout_seconds=5)
        if not is_healthy:
            conn.close()
            raise Exception(f"Direct connection health check failed: {health_message}")
            
        logger.info(f"‚úÖ NEON HARDENING: Using healthy direct connection fallback ({health_message})")
        return conn
        
    except Exception as e:
        logger.error(f"‚ùå NEON HARDENING: Database connection error: {e}")
        raise

def return_connection(conn, is_broken=False):
    """Simplified connection return to pool"""
    try:
        pool = get_connection_pool()
        if is_broken:
            pool.putconn(conn, close=True)
        else:
            pool.putconn(conn)
    except Exception:
        # Fallback: close connection directly
        try:
            conn.close()
        except:
            pass

async def execute_query(query: str, params: Optional[tuple] = None) -> List[Dict]:
    """Execute a SELECT query and return results using connection pool with retry"""
    import psycopg2
    
    def _execute() -> List[Dict]:
        max_retries = 3
        for attempt in range(max_retries):
            conn = None
            try:
                conn = get_connection()
                with conn.cursor() as cursor:
                    cursor.execute(query, params)
                    results = cursor.fetchall()
                    return [dict(row) for row in results] if results else []
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
                # NEON HARDENING: Connection-level errors that indicate dead connections
                if conn:
                    return_connection(conn, is_broken=True)
                    conn = None
                
                # NEON HARDENING: Recreate pool on connection failures to recover from auto-suspend
                error_msg = str(e).lower()
                if any(indicator in error_msg for indicator in ['connection closed', 'server closed', 'ssl connection', 'timeout']):
                    logger.warning(f"üîÑ NEON HARDENING: Detected dead connection, recreating pool: {e}")
                    if recreate_connection_pool():
                        logger.info("‚úÖ NEON HARDENING: Pool recreated, connection should be restored")
                
                if attempt < max_retries - 1:
                    logger.warning(f"NEON HARDENING: Database connection retry {attempt + 1}/{max_retries}: {e}")
                    # Short delay between retries to avoid overwhelming the endpoint
                    time.sleep(0.5 + (attempt * 0.5))
                    continue
                else:
                    logger.error(f"üí• NEON HARDENING: All database connection attempts failed after {max_retries} retries")
                    logger.error(f"   ‚îî‚îÄ Final error: {e}")
                    logger.info("üè• FALLBACK: Returning empty result set to prevent application hang")
                    logger.info("   ‚îî‚îÄ Application will continue with limited functionality")
                    logger.info("   ‚îî‚îÄ Background health probe will attempt automatic recovery")
                    
                    if TEST_STRICT_DB:
                        # ARCHITECT REQUIREMENT 3: Raise exceptions in strict test mode
                        logger.error("‚ö†Ô∏è TEST_STRICT_DB=true - raising exception instead of graceful degradation")
                        raise e
                    
                    return []  # Clear fallback prevents hang
            except Exception as e:
                # Other errors should not be retried
                if conn:
                    return_connection(conn)
                    conn = None
                logger.error(f"Database query error: {e}")
                if TEST_STRICT_DB:
                    # ARCHITECT REQUIREMENT 3: Raise exceptions in strict test mode
                    logger.error("‚ö†Ô∏è TEST_STRICT_DB=true - raising exception instead of graceful degradation")
                    raise e
                logger.warning("üîÑ Database operation failed - returning empty result set for graceful degradation")
                return []  # Graceful degradation instead of crash
            finally:
                if conn:
                    return_connection(conn)
        
        # This should never be reached due to the raise statements above
        return []
    
    return await asyncio.to_thread(_execute)

async def execute_update(query: str, params: Optional[tuple] = None) -> int:
    """Execute an UPDATE/INSERT/DELETE query and return affected rows using connection pool (no retries to prevent duplicates)"""
    import psycopg2
    
    def _execute() -> int:
        conn = None
        try:
            conn = get_connection()
            with conn.cursor() as cursor:
                cursor.execute(query, params)
                conn.commit()
                return cursor.rowcount
        except (psycopg2.OperationalError, psycopg2.InterfaceError) as e:
            # NEON HARDENING: Connection-level errors - close broken connection but don't retry writes
            if conn:
                try:
                    conn.rollback()
                except:
                    pass
                return_connection(conn, is_broken=True)
                conn = None
            
            # NEON HARDENING: Recreate pool on connection failures to recover from auto-suspend
            error_msg = str(e).lower()
            if any(indicator in error_msg for indicator in ['connection closed', 'server closed', 'ssl connection', 'timeout']):
                logger.warning(f"üîÑ NEON HARDENING: Detected dead connection on update, recreating pool: {e}")
                if recreate_connection_pool():
                    logger.info("‚úÖ NEON HARDENING: Pool recreated after update failure")
            
            logger.error(f"üí• NEON HARDENING: Database update connection failed: {e}")
            logger.info("üè• FALLBACK: Update operation aborted to prevent hang")
            logger.info("   ‚îî‚îÄ No data was modified (transaction rolled back)")
            logger.info("   ‚îî‚îÄ Background health probe will attempt automatic recovery")
            
            if TEST_STRICT_DB:
                # ARCHITECT REQUIREMENT 3: Raise exceptions in strict test mode
                logger.error("‚ö†Ô∏è TEST_STRICT_DB=true - raising exception instead of graceful degradation")
                raise e
                
            return 0  # Clear fallback prevents hang
        except Exception as e:
            # Other errors - rollback and return connection
            if conn:
                try:
                    conn.rollback()
                except:
                    pass
                return_connection(conn)
                conn = None
                
            logger.error(f"üí• NEON HARDENING: Database update operation failed: {e}")
            logger.info("üè• FALLBACK: Update operation aborted with clean rollback")
            logger.info("   ‚îî‚îÄ Database remains in consistent state")
            logger.info("   ‚îî‚îÄ Application will continue with degraded functionality")
            
            if TEST_STRICT_DB:
                # ARCHITECT REQUIREMENT 3: Raise exceptions in strict test mode
                logger.error("‚ö†Ô∏è TEST_STRICT_DB=true - raising exception instead of graceful degradation")
                raise e
                
            return 0  # Clear fallback prevents hang
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_execute)

async def run_in_transaction(func, *args, **kwargs):
    """Simplified transaction execution"""
    import psycopg2
    
    def _execute_in_transaction():
        conn = None
        try:
            conn = get_connection()
            original_autocommit = conn.autocommit
            conn.autocommit = False
            
            try:
                result = func(conn, *args, **kwargs)
                conn.commit()
                return result
            except Exception as e:
                conn.rollback()
                raise e
            finally:
                conn.autocommit = original_autocommit
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_execute_in_transaction)

async def init_database():
    """Initialize database tables if they don't exist"""
    def _init():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                # Users table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS users (
                        id SERIAL PRIMARY KEY,
                        telegram_id BIGINT UNIQUE NOT NULL,
                        username VARCHAR(255),
                        first_name VARCHAR(255),
                        last_name VARCHAR(255),
                        wallet_balance DECIMAL(10,2) DEFAULT 0.00,
                        terms_accepted BOOLEAN DEFAULT FALSE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Add terms_accepted column for existing users (safe if column already exists)
                cursor.execute("""
                    ALTER TABLE users 
                    ADD COLUMN IF NOT EXISTS terms_accepted BOOLEAN DEFAULT FALSE
                """)
                
                # User profiles table for WHOIS data
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS user_profiles (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        first_name VARCHAR(255),
                        last_name VARCHAR(255),
                        organization VARCHAR(255),
                        email VARCHAR(255),
                        phone VARCHAR(20),
                        address VARCHAR(500),
                        city VARCHAR(255),
                        state VARCHAR(255),
                        postal_code VARCHAR(20),
                        country VARCHAR(2),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Domains table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domains (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        domain_name VARCHAR(255) UNIQUE NOT NULL,
                        provider_domain_id VARCHAR(255),
                        status VARCHAR(50),
                        nameservers TEXT[],
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Cloudflare zones table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS cloudflare_zones (
                        id SERIAL PRIMARY KEY,
                        domain_name VARCHAR(255) UNIQUE NOT NULL,
                        cf_zone_id VARCHAR(255) UNIQUE NOT NULL,
                        nameservers TEXT[],
                        status VARCHAR(50),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Wallet transactions table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS wallet_transactions (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        transaction_type VARCHAR(50),
                        amount DECIMAL(10,2),
                        currency VARCHAR(10),
                        status VARCHAR(50),
                        payment_id VARCHAR(255),
                        external_txid VARCHAR(255),
                        description TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(external_txid)
                    )
                """)
                
                # MIGRATION: Add auto_proxy_enabled column to domains table for user preference control
                try:
                    cursor.execute("ALTER TABLE domains ADD COLUMN IF NOT EXISTS auto_proxy_enabled BOOLEAN DEFAULT true")
                    logger.info("‚úÖ Database migration: Added auto_proxy_enabled column to domains table")
                except Exception as migration_error:
                    logger.warning(f"Migration warning (auto_proxy_enabled): {migration_error}")
                
                # MIGRATION: Add external_txid column and unique constraint for existing databases
                try:
                    cursor.execute("ALTER TABLE wallet_transactions ADD COLUMN IF NOT EXISTS external_txid VARCHAR(255)")
                    cursor.execute("""
                        DO $$ 
                        BEGIN
                            IF NOT EXISTS (
                                SELECT 1 FROM pg_constraint 
                                WHERE conname = 'wallet_transactions_external_txid_key'
                            ) THEN
                                ALTER TABLE wallet_transactions ADD CONSTRAINT wallet_transactions_external_txid_key UNIQUE(external_txid);
                            END IF;
                        END $$;
                    """)
                    logger.info("‚úÖ Database migration: external_txid column and unique constraint verified")
                except Exception as migration_error:
                    logger.warning(f"‚ö†Ô∏è Database migration warning (non-critical): {migration_error}")
                
                # CRITICAL SECURITY: Add CHECK constraint to prevent negative wallet balances at database level
                try:
                    cursor.execute("""
                        DO $$ 
                        BEGIN
                            IF NOT EXISTS (
                                SELECT 1 FROM pg_constraint 
                                WHERE conname = 'wallet_balance_non_negative'
                            ) THEN
                                ALTER TABLE users ADD CONSTRAINT wallet_balance_non_negative CHECK (wallet_balance >= 0);
                                RAISE NOTICE '‚úÖ SECURITY: wallet_balance_non_negative constraint added to users table';
                            ELSE
                                RAISE NOTICE '‚úÖ SECURITY: wallet_balance_non_negative constraint already exists';
                            END IF;
                        END $$;
                    """)
                    logger.info("üîí CRITICAL SECURITY: Negative balance protection constraint verified at database level")
                except Exception as security_error:
                    logger.error(f"üö´ CRITICAL: Failed to add negative balance protection constraint: {security_error}")
                    raise  # This is critical security - fail initialization if constraint cannot be added
                
                # MIGRATION: Add preferred_language column to users table for multi-language support
                try:
                    cursor.execute("ALTER TABLE users ADD COLUMN IF NOT EXISTS preferred_language VARCHAR(10) DEFAULT NULL")
                    logger.info("‚úÖ Database migration: Added preferred_language column to users table for multi-language support")
                except Exception as migration_error:
                    logger.warning(f"Migration warning (preferred_language): {migration_error}")
                
                # Wallet deposits table (for crypto wallet funding)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS wallet_deposits (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        crypto_currency VARCHAR(10) NOT NULL,
                        usd_amount DECIMAL(10,2) NOT NULL,
                        crypto_amount DECIMAL(18,8),
                        payment_address VARCHAR(255) NOT NULL,
                        status VARCHAR(50) DEFAULT 'pending_payment',
                        confirmations INTEGER DEFAULT 0,
                        blockbee_order_id VARCHAR(255),
                        txid VARCHAR(255),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Domain orders table (for payment tracking with processing state machine)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domain_orders (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        domain_name VARCHAR(255) NOT NULL,
                        status VARCHAR(50) DEFAULT 'pending_payment',
                        payment_address VARCHAR(255),
                        expected_amount DECIMAL(10,2),
                        currency VARCHAR(10),
                        confirmations INTEGER DEFAULT 0,
                        contact_handle VARCHAR(255),
                        blockbee_order_id VARCHAR(255),
                        txid VARCHAR(255),
                        processing_started_at TIMESTAMP,
                        completed_at TIMESTAMP,
                        error_message TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Hosting plans table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS hosting_plans (
                        id SERIAL PRIMARY KEY,
                        plan_name VARCHAR(255) NOT NULL,
                        plan_type VARCHAR(100) NOT NULL,
                        disk_space_gb INTEGER,
                        bandwidth_gb INTEGER,
                        databases INTEGER,
                        email_accounts INTEGER,
                        subdomains INTEGER,
                        monthly_price DECIMAL(10,2),
                        yearly_price DECIMAL(10,2),
                        features TEXT[],
                        is_active BOOLEAN DEFAULT true,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # User hosting subscriptions table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS hosting_subscriptions (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        hosting_plan_id INTEGER REFERENCES hosting_plans(id),
                        domain_name VARCHAR(255),
                        cpanel_username VARCHAR(255),
                        cpanel_password VARCHAR(255),
                        server_ip VARCHAR(45),
                        status VARCHAR(50),
                        billing_cycle VARCHAR(20),
                        next_billing_date DATE,
                        auto_renew BOOLEAN DEFAULT true,
                        last_warning_sent TIMESTAMP NULL DEFAULT NULL,
                        grace_period_started TIMESTAMP NULL DEFAULT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Payment orders table  
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS payment_orders (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        order_type VARCHAR(50),
                        domain_name VARCHAR(255),
                        amount DECIMAL(10,2),
                        currency VARCHAR(10),
                        status VARCHAR(50),
                        payment_address VARCHAR(255),
                        payment_id VARCHAR(255),
                        subscription_id INTEGER REFERENCES hosting_subscriptions(id),
                        order_subtype VARCHAR(50),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # cPanel accounts table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS cpanel_accounts (
                        id SERIAL PRIMARY KEY,
                        subscription_id INTEGER REFERENCES hosting_subscriptions(id),
                        cpanel_username VARCHAR(255) UNIQUE NOT NULL,
                        cpanel_domain VARCHAR(255),
                        quota_mb INTEGER,
                        server_name VARCHAR(255),
                        ip_address VARCHAR(45),
                        status VARCHAR(50),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Domain-hosting bundles table for bundle management
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domain_hosting_bundles (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        domain_registration_intent_id INTEGER REFERENCES domain_registration_intents(id),
                        hosting_provision_intent_id INTEGER REFERENCES hosting_provision_intents(id),
                        bundle_type VARCHAR(50) DEFAULT 'domain_hosting',
                        bundle_status VARCHAR(50) DEFAULT 'pending',
                        total_amount DECIMAL(10,2),
                        discount_applied DECIMAL(10,2) DEFAULT 0.00,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Bundle pricing table for bundle-specific pricing rules
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS bundle_pricing (
                        id SERIAL PRIMARY KEY,
                        bundle_type VARCHAR(50) NOT NULL,
                        domain_tld VARCHAR(10),
                        hosting_plan_id INTEGER REFERENCES hosting_plans(id),
                        base_price DECIMAL(10,2),
                        bundle_discount_percent DECIMAL(5,2),
                        active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Bundle discounts table for promotional discounts
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS bundle_discounts (
                        id SERIAL PRIMARY KEY,
                        discount_code VARCHAR(50) UNIQUE NOT NULL,
                        discount_type VARCHAR(20) NOT NULL,
                        discount_value DECIMAL(10,2),
                        min_bundle_value DECIMAL(10,2),
                        max_uses INTEGER,
                        current_uses INTEGER DEFAULT 0,
                        expires_at TIMESTAMP,
                        active BOOLEAN DEFAULT TRUE,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Callback tokens table for production hardening
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS callback_tokens (
                        id SERIAL PRIMARY KEY,
                        token VARCHAR(32) UNIQUE NOT NULL,
                        user_id BIGINT NOT NULL,
                        callback_data TEXT NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        expires_at TIMESTAMP NOT NULL
                    )
                """)
                
                # CRITICAL: Payment intents table for concurrency-safe payment processing
                # This table provides atomic intent-claim functionality to prevent duplicate address creation
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS payment_intents (
                        id SERIAL PRIMARY KEY,
                        order_id VARCHAR(255) UNIQUE NOT NULL,
                        provider VARCHAR(50) NOT NULL,
                        currency VARCHAR(10) NOT NULL,
                        amount DECIMAL(10,2) NOT NULL,
                        payment_address VARCHAR(255),
                        external_id VARCHAR(255),
                        txid VARCHAR(255),
                        status VARCHAR(50) NOT NULL DEFAULT 'created',
                        expires_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Migration: Fix order_id column type from INTEGER to VARCHAR for string order IDs
                cursor.execute("""
                    DO $$ 
                    BEGIN
                        -- Check if order_id is currently INTEGER
                        IF EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_name = 'payment_intents' 
                            AND column_name = 'order_id' 
                            AND data_type = 'integer'
                        ) THEN
                            -- Drop unique constraint if it exists
                            ALTER TABLE payment_intents DROP CONSTRAINT IF EXISTS payment_intents_order_id_key;
                            -- Change column type from INTEGER to VARCHAR
                            ALTER TABLE payment_intents ALTER COLUMN order_id TYPE VARCHAR(255);
                            -- Recreate unique constraint
                            ALTER TABLE payment_intents ADD CONSTRAINT payment_intents_order_id_key UNIQUE (order_id);
                            RAISE NOTICE 'Migration: Updated payment_intents.order_id from INTEGER to VARCHAR(255)';
                        END IF;
                    END $$;
                """)
                
                # CRITICAL: Provider claims table to prevent duplicate external API calls
                # Uses unique constraint to ensure only one address creation per (order_id, provider)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS provider_claims (
                        id SERIAL PRIMARY KEY,
                        order_id VARCHAR(255) NOT NULL,
                        provider_name VARCHAR(50) NOT NULL,
                        intent_id INTEGER REFERENCES payment_intents(id),
                        idempotency_key VARCHAR(255) NOT NULL,
                        status VARCHAR(50) NOT NULL DEFAULT 'claiming',
                        external_address VARCHAR(255),
                        external_order_id VARCHAR(255),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(order_id, provider_name)
                    )
                """)
                
                # Migration: Fix order_id column type in provider_claims
                cursor.execute("""
                    DO $$ 
                    BEGIN
                        IF EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_name = 'provider_claims' 
                            AND column_name = 'order_id' 
                            AND data_type = 'integer'
                        ) THEN
                            ALTER TABLE provider_claims DROP CONSTRAINT IF EXISTS provider_claims_order_id_provider_name_key;
                            ALTER TABLE provider_claims ALTER COLUMN order_id TYPE VARCHAR(255);
                            ALTER TABLE provider_claims ADD CONSTRAINT provider_claims_order_id_provider_name_key UNIQUE (order_id, provider_name);
                            RAISE NOTICE 'Migration: Updated provider_claims.order_id from INTEGER to VARCHAR(255)';
                        END IF;
                    END $$;
                """)
                
                # Webhook callbacks table for stronger idempotency protection
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS webhook_callbacks (
                        id SERIAL PRIMARY KEY,
                        order_id VARCHAR(255) NOT NULL,
                        confirmation_count INTEGER NOT NULL,
                        callback_type VARCHAR(50) NOT NULL,
                        status VARCHAR(50) NOT NULL DEFAULT 'processing',
                        txid VARCHAR(255),
                        amount_usd DECIMAL(10,2),
                        processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        completed_at TIMESTAMP,
                        provider_name VARCHAR(50),
                        external_callback_id VARCHAR(255),
                        UNIQUE(order_id, confirmation_count, callback_type),
                        UNIQUE(provider_name, external_callback_id) -- Prevent duplicate provider callbacks
                    )
                """)
                
                # Migration: Fix order_id column type in webhook_callbacks
                cursor.execute("""
                    DO $$ 
                    BEGIN
                        IF EXISTS (
                            SELECT 1 FROM information_schema.columns 
                            WHERE table_name = 'webhook_callbacks' 
                            AND column_name = 'order_id' 
                            AND data_type = 'integer'
                        ) THEN
                            ALTER TABLE webhook_callbacks DROP CONSTRAINT IF EXISTS webhook_callbacks_order_id_confirmation_count_callback_type_key;
                            ALTER TABLE webhook_callbacks ALTER COLUMN order_id TYPE VARCHAR(255);
                            ALTER TABLE webhook_callbacks ADD CONSTRAINT webhook_callbacks_order_id_confirmation_count_callback_type_key UNIQUE (order_id, confirmation_count, callback_type);
                            RAISE NOTICE 'Migration: Updated webhook_callbacks.order_id from INTEGER to VARCHAR(255)';
                        END IF;
                    END $$;
                """)
                
                # Create indexes for callback_tokens
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_callback_tokens_user_id ON callback_tokens(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_callback_tokens_expires_at ON callback_tokens(expires_at)")
                
                # Create indexes for payment_intents (critical for concurrent processing)
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_order_id ON payment_intents(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_status ON payment_intents(status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_expires_at ON payment_intents(expires_at)")
                
                # Create indexes for provider_claims (critical for atomic claiming)
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_provider_claims_order_id ON provider_claims(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_provider_claims_intent_id ON provider_claims(intent_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_provider_claims_status ON provider_claims(status)")
                
                # Create indexes for webhook_callbacks (critical for concurrent processing)
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_webhook_callbacks_order_id ON webhook_callbacks(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_webhook_callbacks_status ON webhook_callbacks(status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_webhook_callbacks_processed_at ON webhook_callbacks(processed_at)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_webhook_callbacks_callback_type ON webhook_callbacks(callback_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_webhook_callbacks_provider_external ON webhook_callbacks(provider_name, external_callback_id)")
                
                # Create indexes for wallet_deposits (data integrity)
                cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_wallet_deposits_blockbee_order_id ON wallet_deposits(blockbee_order_id) WHERE blockbee_order_id IS NOT NULL")
                cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_wallet_deposits_txid ON wallet_deposits(txid) WHERE txid IS NOT NULL")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_wallet_deposits_user_id ON wallet_deposits(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_wallet_deposits_payment_address ON wallet_deposits(payment_address)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_wallet_deposits_status ON wallet_deposits(status)")
                
                # Create indexes for domain_orders (data integrity and security)
                cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_domain_orders_blockbee_order_id ON domain_orders(blockbee_order_id) WHERE blockbee_order_id IS NOT NULL")
                cursor.execute("CREATE UNIQUE INDEX IF NOT EXISTS idx_domain_orders_txid ON domain_orders(txid) WHERE txid IS NOT NULL")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_orders_user_id ON domain_orders(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_orders_domain_name ON domain_orders(domain_name)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_orders_status ON domain_orders(status)")
                
                # Create indexes for bundle tables (performance optimization)
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_hosting_bundles_user_id ON domain_hosting_bundles(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_hosting_bundles_status ON domain_hosting_bundles(bundle_status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_hosting_bundles_type ON domain_hosting_bundles(bundle_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_hosting_bundles_domain_intent ON domain_hosting_bundles(domain_registration_intent_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_domain_hosting_bundles_hosting_intent ON domain_hosting_bundles(hosting_provision_intent_id)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_pricing_type ON bundle_pricing(bundle_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_pricing_tld ON bundle_pricing(domain_tld)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_pricing_hosting_plan ON bundle_pricing(hosting_plan_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_pricing_active ON bundle_pricing(active)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_discounts_code ON bundle_discounts(discount_code)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_discounts_type ON bundle_discounts(discount_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_discounts_active ON bundle_discounts(active)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_bundle_discounts_expires_at ON bundle_discounts(expires_at)")
                
                # CRITICAL SECURITY: Add missing columns to existing tables if they don't exist
                # This ensures backward compatibility for existing databases
                try:
                    cursor.execute("ALTER TABLE wallet_deposits ADD COLUMN IF NOT EXISTS txid VARCHAR(255)")
                    cursor.execute("ALTER TABLE domain_orders ADD COLUMN IF NOT EXISTS blockbee_order_id VARCHAR(255)")
                    cursor.execute("ALTER TABLE domain_orders ADD COLUMN IF NOT EXISTS txid VARCHAR(255)")
                    # Add new processing state machine columns
                    cursor.execute("ALTER TABLE domain_orders ADD COLUMN IF NOT EXISTS processing_started_at TIMESTAMP")
                    cursor.execute("ALTER TABLE domain_orders ADD COLUMN IF NOT EXISTS completed_at TIMESTAMP")
                    cursor.execute("ALTER TABLE domain_orders ADD COLUMN IF NOT EXISTS error_message TEXT")
                except Exception as alter_error:
                    logger.warning(f"Column additions may have failed (likely already exist): {alter_error}")
                
                # CRITICAL: Add missing columns to webhook_callbacks table for concurrency fixes
                try:
                    cursor.execute("ALTER TABLE webhook_callbacks ADD COLUMN IF NOT EXISTS provider_name VARCHAR(50)")
                    cursor.execute("ALTER TABLE webhook_callbacks ADD COLUMN IF NOT EXISTS external_callback_id VARCHAR(255)")
                    logger.info("‚úÖ Database migration: Added provider_name and external_callback_id columns to webhook_callbacks")
                except Exception as webhook_migration_error:
                    logger.warning(f"Webhook migration warning: {webhook_migration_error}")
                
                # CRITICAL: Add unique constraint for webhook idempotency (after columns exist)
                try:
                    cursor.execute("""
                        DO $$ 
                        BEGIN
                            IF NOT EXISTS (
                                SELECT 1 FROM pg_constraint 
                                WHERE conname = 'webhook_callbacks_provider_external_key'
                            ) THEN
                                ALTER TABLE webhook_callbacks ADD CONSTRAINT webhook_callbacks_provider_external_key 
                                UNIQUE(provider_name, external_callback_id);
                            END IF;
                        END $$;
                    """)
                    logger.info("‚úÖ Database migration: Added unique constraint on webhook_callbacks(provider_name, external_callback_id)")
                except Exception as constraint_error:
                    logger.warning(f"‚ö†Ô∏è Database constraint migration warning (non-critical): {constraint_error}")
                
                # MIGRATION: Add missing ownership_state column to domains table
                try:
                    cursor.execute("ALTER TABLE domains ADD COLUMN IF NOT EXISTS ownership_state VARCHAR(50)")
                    logger.info("‚úÖ Database migration: Added ownership_state column to domains table")
                except Exception as migration_error:
                    logger.warning(f"Migration warning (ownership_state): {migration_error}")
                
                # CRITICAL MIGRATION: Add missing processing_started_at column to hosting_provision_intents table
                try:
                    cursor.execute("ALTER TABLE hosting_provision_intents ADD COLUMN IF NOT EXISTS processing_started_at TIMESTAMP")
                    logger.info("‚úÖ Database migration: Added processing_started_at column to hosting_provision_intents table")
                except Exception as migration_error:
                    logger.warning(f"Migration warning (hosting processing_started_at): {migration_error}")
                
                # CRITICAL MIGRATION SAFEGUARD: Verify and prevent order_id column type conflicts
                # This prevents the migration error by ensuring schema consistency
                try:
                    logger.info("üîç Running migration safeguard checks for order_id columns...")
                    
                    # Check current column types for order_id across all relevant tables
                    order_id_tables = ["payment_intents", "payment_intents_unified", "provider_claims", "webhook_callbacks"]
                    
                    for table_name in order_id_tables:
                        # Check if table exists and get order_id column type
                        cursor.execute("""
                            SELECT data_type 
                            FROM information_schema.columns 
                            WHERE table_name = %s AND column_name = 'order_id'
                        """, (table_name,))
                        result = cursor.fetchone()
                        
                        if result:
                            current_type = result[0] if isinstance(result, tuple) else result['data_type']
                            
                            # Define expected types for each table
                            expected_types = {
                                'payment_intents': 'character varying',  # String-based order IDs
                                'provider_claims': 'character varying',  # String-based order IDs  
                                'webhook_callbacks': 'character varying',  # String-based order IDs
                                'payment_intents_unified': 'integer'  # Integer references to orders table
                            }
                            
                            expected_type = expected_types.get(table_name, 'integer')  # Default to integer for other tables
                            
                            if current_type == expected_type:
                                type_name = "VARCHAR" if expected_type == 'character varying' else "INTEGER"
                                logger.info(f"‚úÖ MIGRATION SAFEGUARD: {table_name}.order_id is already {type_name} (correct)")
                            else:
                                expected_name = "VARCHAR" if expected_type == 'character varying' else "INTEGER"
                                current_name = "VARCHAR" if current_type == 'character varying' else current_type.upper()
                                logger.warning(f"‚ö†Ô∏è MIGRATION SAFEGUARD: {table_name}.order_id is {current_name} but should be {expected_name}")
                                logger.info(f"üìã This inconsistency has been noted but not automatically fixed to preserve data integrity")
                        else:
                            logger.debug(f"MIGRATION SAFEGUARD: Table {table_name} does not exist or has no order_id column")
                    
                    logger.info("‚úÖ MIGRATION SAFEGUARD: order_id column type verification complete")
                except Exception as safeguard_error:
                    logger.warning(f"‚ö†Ô∏è Migration safeguard warning (non-critical): {safeguard_error}")
                    # Don't fail initialization due to safeguard issues
                
                # Domain searches table (ephemeral search history)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domain_searches (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        domain_name VARCHAR(255) NOT NULL,
                        availability_snapshot JSONB,
                        price_snapshot JSONB,
                        nameservers_snapshot JSONB,
                        search_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Domain registration intents table (prevent duplicate registrations)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domain_registration_intents (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        domain_name VARCHAR(255) NOT NULL,
                        quote_price DECIMAL(10,2) NOT NULL,
                        currency VARCHAR(10) DEFAULT 'USD',
                        status VARCHAR(50) DEFAULT 'created',
                        idempotency_key VARCHAR(255) UNIQUE NOT NULL,
                        provider_domain_id VARCHAR(255),
                        completed_at TIMESTAMP,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Domain notifications table (prevent duplicate notifications)
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS domain_notifications (
                        id SERIAL PRIMARY KEY,
                        order_id VARCHAR(255) NOT NULL,
                        message_type VARCHAR(100) NOT NULL,
                        user_id INTEGER REFERENCES users(id),
                        message_content TEXT,
                        sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        UNIQUE(order_id, message_type)
                    )
                """)
                
                # CRITICAL: Refund tracking table for idempotent refund processing
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS refund_tracking (
                        id SERIAL PRIMARY KEY,
                        order_id INTEGER NOT NULL,
                        user_id INTEGER REFERENCES users(id),
                        domain_name VARCHAR(255) NOT NULL,
                        status VARCHAR(50) DEFAULT 'processing',
                        failure_phase VARCHAR(100),
                        failure_reason TEXT,
                        refund_method VARCHAR(50),
                        provider_status VARCHAR(50),
                        provider_response JSONB,
                        error_message TEXT,
                        idempotency_key VARCHAR(255) UNIQUE NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        completed_at TIMESTAMP,
                        UNIQUE(order_id, user_id, domain_name)
                    )
                """)
                
                # Create indexes for refund_tracking (critical for performance)
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refund_tracking_order_id ON refund_tracking(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refund_tracking_user_id ON refund_tracking(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refund_tracking_status ON refund_tracking(status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refund_tracking_domain_name ON refund_tracking(domain_name)")
                
                # üö® CRITICAL SECURITY FIX: Add cpanel_secret_ref column and NULL plaintext passwords
                try:
                    cursor.execute("ALTER TABLE hosting_subscriptions ADD COLUMN IF NOT EXISTS cpanel_secret_ref VARCHAR(255)")
                    # IMMEDIATELY NULL all existing plaintext passwords for security
                    cursor.execute("UPDATE hosting_subscriptions SET cpanel_password = NULL WHERE cpanel_password IS NOT NULL")
                    logger.info("üîí CRITICAL SECURITY FIX: Added cpanel_secret_ref column and nullified all plaintext passwords")
                except Exception as security_migration_error:
                    logger.error(f"üö´ CRITICAL SECURITY MIGRATION FAILED: {security_migration_error}")
                    raise  # This is critical security - fail initialization if migration fails
                
                # üèóÔ∏è PHASE 1: Add unified tables for order management system
                
                # Unified orders table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS orders (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        status VARCHAR(50) NOT NULL,
                        total_amount NUMERIC(12,2),
                        currency VARCHAR(10) DEFAULT 'USD',
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Unified order items table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS order_items (
                        id SERIAL PRIMARY KEY,
                        order_id INTEGER REFERENCES orders(id),
                        item_type VARCHAR(50) NOT NULL,
                        item_name VARCHAR(255) NOT NULL,
                        quantity INTEGER DEFAULT 1,
                        unit_price NUMERIC(12,2),
                        total_price NUMERIC(12,2),
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Unified payment intents table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS payment_intents_unified (
                        id SERIAL PRIMARY KEY,
                        order_id INTEGER REFERENCES orders(id),
                        amount NUMERIC(12,2) NOT NULL,
                        currency VARCHAR(10) DEFAULT 'USD',
                        status VARCHAR(50) NOT NULL DEFAULT 'created',
                        payment_method VARCHAR(50),
                        payment_provider VARCHAR(50),
                        payment_provider_id VARCHAR(255),
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Unified ledger transactions table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS ledger_transactions (
                        id SERIAL PRIMARY KEY,
                        user_id INTEGER REFERENCES users(id),
                        order_id INTEGER REFERENCES orders(id),
                        transaction_type VARCHAR(50) NOT NULL,
                        amount NUMERIC(12,2) NOT NULL,
                        currency VARCHAR(10) DEFAULT 'USD',
                        balance_before NUMERIC(12,2),
                        balance_after NUMERIC(12,2),
                        description TEXT,
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Unified refunds table
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS refunds_unified (
                        id SERIAL PRIMARY KEY,
                        order_id INTEGER REFERENCES orders(id),
                        user_id INTEGER REFERENCES users(id),
                        amount NUMERIC(12,2) NOT NULL,
                        currency VARCHAR(10) DEFAULT 'USD',
                        reason VARCHAR(255),
                        status VARCHAR(50) DEFAULT 'pending',
                        payment_provider VARCHAR(50),
                        payment_provider_refund_id VARCHAR(255),
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Create indexes for Phase 1 unified tables
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_orders_user_id ON orders(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_orders_status ON orders(status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_orders_created_at ON orders(created_at)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_order_items_order_id ON order_items(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_order_items_item_type ON order_items(item_type)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_unified_order_id ON payment_intents_unified(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_unified_status ON payment_intents_unified(status)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_payment_intents_unified_payment_provider ON payment_intents_unified(payment_provider)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_ledger_transactions_user_id ON ledger_transactions(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_ledger_transactions_order_id ON ledger_transactions(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_ledger_transactions_type ON ledger_transactions(transaction_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_ledger_transactions_created_at ON ledger_transactions(created_at)")
                
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refunds_unified_order_id ON refunds_unified(order_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refunds_unified_user_id ON refunds_unified(user_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_refunds_unified_status ON refunds_unified(status)")
                
                logger.info("‚úÖ PHASE 1: All unified tables created successfully (orders, order_items, payment_intents_unified, ledger_transactions, refunds_unified)")
                
                conn.commit()
                logger.info("‚úÖ Database tables initialized successfully")
        finally:
            return_connection(conn)
    
    await asyncio.to_thread(_init)
    
    # CRITICAL SECURITY: Verify all security constraints after initialization
    security_verified = await verify_security_constraints()
    
    # Log final security status for production debugging
    security_status = get_security_status()
    logger.info("üîç FINAL SECURITY STATUS:")
    logger.info(f"   ‚Ä¢ Security Verified: {security_status['security_verified']}")
    logger.info(f"   ‚Ä¢ Safe Mode: {security_status['safe_mode_enabled']}")  
    logger.info(f"   ‚Ä¢ Financial Operations: {security_status['financial_operations_allowed']}")
    logger.info(f"   ‚Ä¢ Degraded Startup Allowed: {security_status['degraded_startup_allowed']}")
    
    if security_verified:
        logger.info("‚úÖ DATABASE INITIALIZATION COMPLETE: Full security mode active")
    else:
        logger.warning("‚ö†Ô∏è DATABASE INITIALIZATION COMPLETE: Running in safe mode with limited functionality")
    
    # NEON HARDENING: Start background health probe after successful initialization
    try:
        await start_health_probe()
        logger.info("‚úÖ NEON HARDENING: Database health monitoring started")
    except Exception as probe_error:
        logger.warning(f"‚ö†Ô∏è NEON HARDENING: Could not start health probe: {probe_error}")

async def verify_security_constraints() -> bool:
    """
    CRITICAL SECURITY: Verify all financial security constraints are in place
    This function ensures the wallet system is bulletproof against negative balances
    
    Returns True if constraints are verified, False if system should run in safe mode
    """
    global _security_constraints_verified, _safe_mode_enabled, _security_verification_cache_time
    
    try:
        # PERFORMANCE OPTIMIZATION: Check if verification was recently successful
        current_time = time.time()
        if (_security_constraints_verified and 
            _security_verification_cache_time > 0 and 
            (current_time - _security_verification_cache_time) < _security_verification_cache_duration):
            cache_age = int(current_time - _security_verification_cache_time)
            logger.info(f"‚ö° SECURITY VERIFICATION CACHED: Skipping verification (verified {cache_age}s ago)")
            logger.info("‚úÖ FINANCIAL OPERATIONS: Enabled (cached verification)")
            return True
        
        logger.info("üîç Starting security constraint verification...")
        
        # Phase 1: Verify database CHECK constraint exists
        constraints = await execute_query(
            """SELECT cc.constraint_name, cc.check_clause 
               FROM information_schema.check_constraints cc
               JOIN information_schema.table_constraints tc ON cc.constraint_name = tc.constraint_name
               WHERE tc.table_name = 'users' AND cc.constraint_name = 'wallet_balance_non_negative'"""
        )
        
        if constraints:
            logger.info("üîí SECURITY VERIFIED: wallet_balance_non_negative constraint is active")
            logger.info(f"üîí Constraint: {constraints[0]['check_clause']}")
        else:
            constraint_error = "CRITICAL: wallet_balance_non_negative constraint is MISSING from users table"
            logger.error(f"üö´ {constraint_error}")
            return await _handle_security_constraint_failure(constraint_error, "missing_constraint")
        
        # Phase 2: Test constraint functionality
        test_result = await _test_negative_balance_protection()
        if not test_result:
            test_error = "CRITICAL: Security constraint test failed - constraint may not be working"
            logger.error(f"üö´ {test_error}")
            return await _handle_security_constraint_failure(test_error, "constraint_test_failed")
        
        # Phase 3: All verifications passed
        _security_constraints_verified = True
        _safe_mode_enabled = False
        _security_verification_cache_time = current_time  # Cache successful verification
        logger.info("‚úÖ SECURITY VERIFICATION COMPLETE: All wallet security constraints verified and working")
        logger.info("‚úÖ FINANCIAL OPERATIONS: Enabled (all security checks passed)")
        return True
        
    except Exception as e:
        error_msg = f"Security verification failed with exception: {e}"
        logger.error(f"üö´ CRITICAL SECURITY EXCEPTION: {error_msg}")
        return await _handle_security_constraint_failure(error_msg, "verification_exception")

async def _handle_security_constraint_failure(error_msg: str, failure_type: str) -> bool:
    """
    Handle security constraint verification failure with graceful degradation
    
    Returns True if system should continue (safe mode), False if system should halt
    """
    global _security_constraints_verified, _safe_mode_enabled
    
    # Log the failure with full context
    logger.error(f"üö´ SECURITY CONSTRAINT FAILURE: {error_msg}")
    logger.error(f"üö´ Failure Type: {failure_type}")
    logger.error(f"üö´ Current Configuration: ALLOW_DEGRADED_STARTUP={_allow_degraded_startup}")
    
    # Check if degraded startup is allowed
    if _allow_degraded_startup:
        # Enable safe mode for graceful degradation
        _security_constraints_verified = False
        enable_safe_mode(f"Security verification failed: {failure_type}")
        
        logger.warning("üü° GRACEFUL DEGRADATION: System will start in SAFE MODE")
        logger.warning("üü° SAFE MODE RESTRICTIONS:")
        logger.warning("üü°   - ALL financial operations disabled")
        logger.warning("üü°   - Wallet deposits/withdrawals blocked")
        logger.warning("üü°   - Domain purchases blocked")
        logger.warning("üü°   - Read-only operations only")
        logger.warning("üü° ADMINISTRATOR ACTION REQUIRED: Fix security constraints and restart")
        
        return True  # Allow system to continue in safe mode
    else:
        # Strict mode - system cannot start without security constraints
        _security_constraints_verified = False
        _safe_mode_enabled = True
        
        logger.error("üö´ STRICT MODE: System cannot start without verified security constraints")
        logger.error("üö´ ADMINISTRATOR ACTION REQUIRED:")
        logger.error("üö´   1. Fix database security constraints")
        logger.error("üö´   2. Ensure wallet_balance_non_negative constraint exists")
        logger.error("üö´   3. OR set ALLOW_DEGRADED_STARTUP=true for emergency operations")
        logger.error("üö´ SYSTEM STARTUP BLOCKED for security reasons")
        
        # In strict mode, we still raise the exception to prevent startup
        raise Exception(f"SECURITY CONSTRAINT FAILURE: {error_msg} (set ALLOW_DEGRADED_STARTUP=true to override)")

    return False  # Should not be reached

async def _test_negative_balance_protection() -> bool:
    """
    Test that the security constraints actually prevent negative balances
    This runs a quick verification test to ensure protections are working
    
    Returns True if constraints work properly, False if they fail
    """
    test_user_id = None
    
    try:
        # Test 1: Try direct SQL update to create negative balance (should be blocked by constraint)
        test_user_id = 999999999
        
        logger.info("üîç Starting security constraint functionality test...")
        
        # Clean up any test data first
        await execute_update("DELETE FROM users WHERE telegram_id = %s", (test_user_id,))
        
        # Create test user with balance of 1.00
        rows_inserted = await execute_update(
            "INSERT INTO users (telegram_id, wallet_balance) VALUES (%s, %s)", 
            (test_user_id, 1.00)
        )
        
        if rows_inserted != 1:
            logger.error("üö´ TEST SETUP FAILED: Could not create test user")
            return False
        
        # Try to force negative balance via direct SQL (should fail due to constraint)
        # Use direct database connection to bypass graceful degradation logic
        import psycopg2
        conn = None
        constraint_blocked_negative = False
        
        try:
            conn = get_connection()
            with conn.cursor() as cursor:
                cursor.execute(
                    "UPDATE users SET wallet_balance = -10.00 WHERE telegram_id = %s", 
                    (test_user_id,)
                )
                conn.commit()
            # If we reach here, the constraint failed to prevent negative balance
            logger.error("üö´ CONSTRAINT TEST FAILED: Database constraint did not block negative balance")
            return False
        except psycopg2.IntegrityError as constraint_error:
            # This is the expected constraint violation - security is working!
            error_msg = str(constraint_error)
            if ("wallet_balance_non_negative" in error_msg or 
                "violates check constraint" in error_msg):
                logger.info("üîí CONSTRAINT TEST PASSED: Negative balance blocked by database constraint")
                constraint_blocked_negative = True
                if conn:
                    conn.rollback()  # Rollback the failed transaction
            else:
                logger.warning(f"Unexpected constraint error (may still be valid): {constraint_error}")
                constraint_blocked_negative = True  # Assume it's working if any constraint error
                if conn:
                    conn.rollback()
        except Exception as unexpected_error:
            logger.error(f"Unexpected error during constraint test: {unexpected_error}")
            if conn:
                conn.rollback()
            return False
        finally:
            if conn:
                return_connection(conn)
        
        if not constraint_blocked_negative:
            logger.error("üö´ CONSTRAINT TEST FAILED: No constraint violation detected")
            return False
        
        # Test 2: Verify balance is still 1.00 (unchanged)
        balance_check = await execute_query(
            "SELECT wallet_balance FROM users WHERE telegram_id = %s", 
            (test_user_id,)
        )
        
        if not balance_check:
            logger.error("üö´ INTEGRITY TEST FAILED: Test user disappeared")
            return False
            
        current_balance = float(balance_check[0]['wallet_balance'])
        if current_balance == 1.00:
            logger.info("üîí INTEGRITY TEST PASSED: Balance unchanged after constraint violation")
        else:
            logger.error(f"üö´ INTEGRITY TEST FAILED: Balance changed to {current_balance} (expected 1.00)")
            return False
        
        logger.info("‚úÖ SECURITY CONSTRAINT TEST COMPLETE: Database-level negative balance protection verified")
        return True
        
    except Exception as e:
        logger.error(f"üö´ SECURITY CONSTRAINT TEST EXCEPTION: {e}")
        return False
        
    finally:
        # Clean up test data
        try:
            if test_user_id is not None:
                cleanup_result = await execute_update("DELETE FROM users WHERE telegram_id = %s", (test_user_id,))
                logger.debug(f"üßπ Test cleanup: Removed {cleanup_result} test records")
        except Exception as cleanup_error:
            logger.warning(f"Test cleanup warning (non-critical): {cleanup_error}")

# User management functions
async def get_or_create_user(telegram_id: int, username: Optional[str] = None, first_name: Optional[str] = None, last_name: Optional[str] = None) -> Dict:
    """Get existing user or create new one using efficient UPSERT"""
    # Use PostgreSQL UPSERT (INSERT ... ON CONFLICT) for single-query operation
    query = """
        INSERT INTO users (telegram_id, username, first_name, last_name, wallet_balance, terms_accepted, created_at, updated_at)
        VALUES (%s, %s, %s, %s, 0.00, FALSE, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        ON CONFLICT (telegram_id) 
        DO UPDATE SET 
            username = COALESCE(EXCLUDED.username, users.username),
            first_name = COALESCE(EXCLUDED.first_name, users.first_name),
            last_name = COALESCE(EXCLUDED.last_name, users.last_name),
            updated_at = CURRENT_TIMESTAMP
        RETURNING *;
    """
    
    # Single query that either inserts new user or updates existing one and returns the result
    users = await execute_query(query, (telegram_id, username, first_name, last_name))
    
    if not users:
        raise Exception(f"Failed to create or retrieve user {telegram_id} - database operation returned no results")
    
    return users[0]

async def get_or_create_user_with_status(telegram_id: int, username: Optional[str] = None, 
                                       first_name: Optional[str] = None, last_name: Optional[str] = None) -> Dict:
    """
    PERFORMANCE OPTIMIZED: Get/create user with caching and simplified query
    Includes timing logs and cache layer for frequent users
    """
    import time
    start_time = time.perf_counter()
    
    # Check cache first for existing users (most /start commands are from existing users)
    from performance_cache import get_cached
    cached_user = get_cached(f'user_data_{telegram_id}')
    
    if cached_user:
        # Update cached profile data if provided (but don't hit DB for this)
        if username and cached_user.get('username') != username:
            cached_user['username'] = username
        if first_name and cached_user.get('first_name') != first_name:
            cached_user['first_name'] = first_name
        if last_name and cached_user.get('last_name') != last_name:
            cached_user['last_name'] = last_name
            
        elapsed = (time.perf_counter() - start_time) * 1000
        logger.info(f"‚ö° USER CACHE HIT: {telegram_id} in {elapsed:.1f}ms")
        return cached_user
    
    # Cache miss - query database with optimized minimal query
    query = """
        INSERT INTO users (telegram_id, username, first_name, last_name, wallet_balance, terms_accepted, created_at, updated_at)
        VALUES (%s, %s, %s, %s, 0.00, FALSE, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        ON CONFLICT (telegram_id) 
        DO UPDATE SET 
            username = COALESCE(EXCLUDED.username, users.username),
            first_name = COALESCE(EXCLUDED.first_name, users.first_name),
            last_name = COALESCE(EXCLUDED.last_name, users.last_name),
            updated_at = CURRENT_TIMESTAMP
        RETURNING id, telegram_id, username, first_name, last_name, 
                  wallet_balance, terms_accepted, created_at, updated_at;
    """
    
    users = await execute_query(query, (telegram_id, username, first_name, last_name))
    
    if not users:
        raise Exception(f"Failed to create or retrieve user {telegram_id} - database operation returned no results")
    
    user_data = users[0]
    
    # Enrich and cache the result
    enriched_data = {
        **user_data,
        'terms_accepted_bool': bool(user_data['terms_accepted']),
        'wallet_balance_float': float(user_data['wallet_balance'] or 0.00)
    }
    
    # Cache for 5 minutes (frequent users will hit cache on subsequent /start)
    from performance_cache import set_cached
    set_cached(f'user_data_{telegram_id}', enriched_data, 300)  # 5 minutes
    
    elapsed = (time.perf_counter() - start_time) * 1000
    logger.info(f"‚ö° USER DB QUERY: {telegram_id} in {elapsed:.1f}ms (cached for 5min)")
    
    return enriched_data

async def accept_user_terms(telegram_id: int) -> bool:
    """Mark user as having accepted terms and services"""
    try:
        rows_updated = await execute_update(
            "UPDATE users SET terms_accepted = TRUE, updated_at = CURRENT_TIMESTAMP WHERE telegram_id = %s",
            (telegram_id,)
        )
        
        # CACHE INVALIDATION: Clear specific user cache after state change
        if rows_updated > 0:
            from performance_cache import delete_cached
            # Invalidate cached user data for this specific user to prevent stale data
            delete_cached(f'user_data_{telegram_id}')
            logger.info(f"‚úÖ Cache invalidated for user {telegram_id} after terms acceptance")
            
        return rows_updated > 0
    except Exception as e:
        logger.error(f"Error updating terms acceptance for user {telegram_id}: {e}")
        return False

async def has_user_accepted_terms(telegram_id: int) -> bool:
    """Check if user has accepted terms and services"""
    try:
        result = await execute_query(
            "SELECT terms_accepted FROM users WHERE telegram_id = %s", 
            (telegram_id,)
        )
        if result:
            terms_status = bool(result[0]['terms_accepted'])
            logger.info(f"üîç DB TERMS CHECK: User {telegram_id} has terms_accepted = {result[0]['terms_accepted']} (bool: {terms_status})")
            return terms_status
        logger.warning(f"‚ö†Ô∏è DB TERMS CHECK: User {telegram_id} not found in database")
        return False
    except Exception as e:
        logger.error(f"‚ùå ERROR checking terms acceptance for user {telegram_id}: {e}")
        return False

async def get_all_user_telegram_ids() -> List[int]:
    """Get all user telegram IDs for broadcasting"""
    try:
        result = await execute_query(
            "SELECT telegram_id FROM users WHERE terms_accepted = TRUE ORDER BY created_at DESC"
        )
        return [row['telegram_id'] for row in result] if result else []
    except Exception as e:
        logger.error(f"‚ùå ERROR getting user telegram IDs for broadcast: {e}")
        return []

async def get_telegram_id_from_user_id(user_id: int) -> Optional[int]:
    """Get telegram_id from internal user_id for notifications"""
    try:
        result = await execute_query(
            "SELECT telegram_id FROM users WHERE id = %s", 
            (user_id,)
        )
        if result:
            return result[0]['telegram_id']
        logger.warning(f"‚ö†Ô∏è User ID {user_id} not found in database")
        return None
    except Exception as e:
        logger.error(f"‚ùå ERROR getting telegram_id for user_id {user_id}: {e}")
        return None

# Domain management functions
async def save_domain(user_id: int, domain_name: str, provider_domain_id: Optional[str] = None, status: str = 'pending') -> bool:
    """Save domain to database"""
    try:
        await execute_update(
            "INSERT INTO domains (user_id, domain_name, provider_domain_id, status) VALUES (%s, %s, %s, %s)",
            (user_id, domain_name, provider_domain_id, status)
        )
        return True
    except Exception as e:
        logger.error(f"Error saving domain: {e}")
        return False

async def get_user_domains(user_id: int) -> List[Dict]:
    """Get all domains for a user"""
    return await execute_query("SELECT * FROM domains WHERE user_id = %s ORDER BY created_at DESC", (user_id,))

async def get_domain_by_name(domain_name: str) -> Optional[Dict]:
    """Get domain record by domain name from database"""
    query = """
        SELECT * 
        FROM domains 
        WHERE domain_name = %s
    """
    results = await execute_query(query, (domain_name,))
    if results:
        return dict(results[0])
    return None

async def get_domain_provider_id(domain_name: str) -> Optional[str]:
    """Get provider domain ID for a specific domain from database"""
    query = """
        SELECT provider_domain_id 
        FROM domains 
        WHERE domain_name = %s
    """
    results = await execute_query(query, (domain_name,))
    if results:
        return results[0].get('provider_domain_id')
    return None

async def update_domain_nameservers(domain_name: str, nameservers: List[str]) -> bool:
    """Update nameservers for a domain in the database"""
    try:
        await execute_update(
            "UPDATE domains SET nameservers = %s, updated_at = CURRENT_TIMESTAMP WHERE domain_name = %s",
            (nameservers, domain_name)
        )
        logger.info(f"‚úÖ Updated nameservers in database for domain: {domain_name}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating nameservers for {domain_name}: {e}")
        return False

async def get_domain_nameservers(domain_name: str) -> Optional[List[str]]:
    """Get stored nameservers for a domain from database"""
    query = """
        SELECT nameservers 
        FROM domains 
        WHERE domain_name = %s
    """
    results = await execute_query(query, (domain_name,))
    if results and results[0].get('nameservers'):
        return list(results[0]['nameservers'])
    return None

async def get_domain_auto_proxy_enabled(domain_name: str) -> bool:
    """Get auto-proxy enabled setting for a domain from database"""
    query = """
        SELECT auto_proxy_enabled 
        FROM domains 
        WHERE domain_name = %s
    """
    results = await execute_query(query, (domain_name,))
    if results and results[0].get('auto_proxy_enabled') is not None:
        return bool(results[0]['auto_proxy_enabled'])
    return True  # Default to enabled if not set

async def set_domain_auto_proxy_enabled(domain_name: str, enabled: bool) -> bool:
    """Update auto-proxy enabled setting for a domain in the database"""
    try:
        await execute_update(
            "UPDATE domains SET auto_proxy_enabled = %s, updated_at = CURRENT_TIMESTAMP WHERE domain_name = %s",
            (enabled, domain_name)
        )
        logger.info(f"‚úÖ Updated auto-proxy setting for domain {domain_name}: {enabled}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating auto-proxy setting for {domain_name}: {e}")
        return False

# NEW 3-TABLE STATE MANAGEMENT SYSTEM
async def log_domain_search(user_id: int, domain_name: str, search_result: Dict[str, Any]) -> bool:
    """Log domain search to domain_searches table (ephemeral search history)"""
    try:
        # Extract snapshots from search_result
        availability_data = {
            'available': search_result.get('available', True),
            'premium': search_result.get('premium', False),
            'status': search_result.get('status', 'unknown')
        }
        
        price_data = {
            'registration_price': search_result.get('registration_price'),
            'currency': 'USD'
        }
        
        nameservers_data = {
            'nameservers': search_result.get('nameservers'),
            'using_cloudflare_ns': search_result.get('using_cloudflare_ns', False)
        }
        
        await execute_update(
            """INSERT INTO domain_searches 
               (user_id, domain_name, availability_snapshot, price_snapshot, nameservers_snapshot) 
               VALUES (%s, %s, %s, %s, %s)""",
            (
                user_id, 
                domain_name, 
                json.dumps(availability_data),
                json.dumps(price_data),
                json.dumps(nameservers_data)
            )
        )
        logger.info(f"‚úÖ Logged domain search for {domain_name} by user {user_id}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error logging domain search for {domain_name}: {e}")
        return False

async def create_registration_intent(user_id: int, domain_name: str, estimated_price: float, payment_data: Optional[Dict[str, Any]] = None) -> Optional[int]:
    """Create registration intent in domain_registration_intents table"""
    try:
        import uuid
        idempotency_key = str(uuid.uuid4())
        
        result = await execute_query(
            """INSERT INTO domain_registration_intents 
               (user_id, domain_name, quote_price, currency, status, idempotency_key) 
               VALUES (%s, %s, %s, %s, %s, %s) 
               RETURNING id""",
            (user_id, domain_name, estimated_price, 'USD', 'created', idempotency_key)
        )
        if result:
            intent_id = result[0]['id']
            logger.info(f"‚úÖ Created registration intent {intent_id} for {domain_name} by user {user_id}")
            return intent_id
        return None
    except Exception as e:
        logger.error(f"‚ùå Error creating registration intent for {domain_name}: {e}")
        return None

async def update_intent_status(intent_id: int, status: str, provider_data: Optional[Dict[str, Any]] = None) -> bool:
    """Update registration intent status"""
    try:
        await execute_update(
            """UPDATE domain_registration_intents 
               SET status = %s, updated_at = CURRENT_TIMESTAMP 
               WHERE id = %s""",
            (status, intent_id)
        )
        logger.info(f"‚úÖ Updated intent {intent_id} status to {status}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating intent {intent_id}: {e}")
        return False

async def finalize_domain_registration(intent_id: int, provider_domain_id: str) -> bool:
    """Finalize domain registration by moving from intent to domains table with verified ownership"""
    try:
        # Get intent details
        intent_result = await execute_query(
            "SELECT user_id, domain_name FROM domain_registration_intents WHERE id = %s",
            (intent_id,)
        )
        if not intent_result:
            logger.error(f"‚ùå Intent {intent_id} not found for finalization")
            return False
            
        intent = intent_result[0]
        
        # Create authoritative domain entry with verified ownership
        await execute_update(
            """INSERT INTO domains 
               (user_id, domain_name, provider_domain_id, ownership_state, status, created_at) 
               VALUES (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP)""",
            (
                intent['user_id'], 
                intent['domain_name'], 
                provider_domain_id,
                'internal_owned',  # Verified ownership through registration
                'active'
            )
        )
        
        # Mark intent as completed
        await execute_update(
            """UPDATE domain_registration_intents 
               SET status = %s, provider_domain_id = %s, completed_at = CURRENT_TIMESTAMP 
               WHERE id = %s""",
            ('completed', provider_domain_id, intent_id)
        )
        
        logger.info(f"‚úÖ Finalized domain registration for {intent['domain_name']} - intent {intent_id}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error finalizing domain registration for intent {intent_id}: {e}")
        return False

async def get_active_registration_intent(user_id: int, domain_name: str) -> Optional[Dict]:
    """Check for active registration intent for a domain by a user"""
    try:
        result = await execute_query(
            """SELECT * FROM domain_registration_intents 
               WHERE user_id = %s AND domain_name = %s AND status IN ('initiated', 'payment_pending', 'payment_confirmed')
               ORDER BY created_at DESC LIMIT 1""",
            (user_id, domain_name)
        )
        return dict(result[0]) if result else None
    except Exception as e:
        logger.error(f"‚ùå Error checking active intent for {domain_name}: {e}")
        return None

async def check_domain_ownership_state(domain_name: str) -> Optional[str]:
    """Check ownership state of domain in domains table"""
    try:
        result = await execute_query(
            "SELECT ownership_state FROM domains WHERE domain_name = %s",
            (domain_name,)
        )
        return result[0]['ownership_state'] if result else None
    except Exception as e:
        logger.error(f"‚ùå Error checking ownership state for {domain_name}: {e}")
        return None

async def get_domain_search_history(user_id: int, domain_name: str, limit: int = 5) -> List[Dict]:
    """Get recent search history for a domain by user"""
    try:
        result = await execute_query(
            """SELECT * FROM domain_searches 
               WHERE user_id = %s AND domain_name = %s 
               ORDER BY search_timestamp DESC LIMIT %s""",
            (user_id, domain_name, limit)
        )
        return [dict(row) for row in result] if result else []
    except Exception as e:
        logger.error(f"‚ùå Error getting search history for {domain_name}: {e}")
        return []


# ====================================================================
# HOSTING PROVISION INTENTS - PREVENT DUPLICATE HOSTING ACCOUNTS
# ====================================================================

async def create_hosting_intent(user_id: int, domain_name: Optional[str], hosting_plan_id: int, estimated_price: float, payment_data: Optional[Dict[str, Any]] = None, service_type: str = 'hosting_only') -> Optional[int]:
    """
    Create hosting provision intent to prevent duplicate hosting accounts
    FIXED: Uses proper idempotent insert behavior with constraint handling
    """
    try:
        # Resolve domain_name to domain_id if provided
        domain_id = None
        if domain_name:
            domain_id = await get_domain_id_by_name(domain_name)
        
        # First, try to get existing active intent for same user/domain/plan/service combination
        # CRITICAL FIX: Include service_type in WHERE clause to prevent cross-service intent reuse
        existing_intent = await execute_query(
            """SELECT id, service_type, domain_name FROM hosting_provision_intents 
               WHERE user_id = %s 
               AND (
                   (domain_id = %s) OR 
                   (%s IS NULL AND domain_id IS NULL AND COALESCE(domain_name, '') = COALESCE(%s, ''))
               )
               AND hosting_plan_id = %s 
               AND service_type = %s
               AND status IN ('pending_payment', 'provisioning')
               ORDER BY created_at DESC LIMIT 1""",
            (user_id, domain_id, domain_id, domain_name or '', hosting_plan_id, service_type)
        )
        
        if existing_intent:
            intent_id = existing_intent[0]['id']
            existing_service_type = existing_intent[0]['service_type']
            existing_domain_name = existing_intent[0]['domain_name']
            
            domain_info = f"domain '{domain_name}'" if domain_name else "no domain"
            logger.info(f"‚ôªÔ∏è Returning existing hosting intent {intent_id} for {domain_info} by user {user_id}")
            
            # Update the price, service type, and domain for existing intents to ensure consistency
            await execute_update(
                """UPDATE hosting_provision_intents 
                   SET quote_price = %s, service_type = %s, domain_name = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (estimated_price, service_type, domain_name, intent_id)
            )
            logger.info(f"üîÑ Updated existing intent {intent_id}: price=${estimated_price:.2f}, service={service_type}")
            return intent_id
        
        # Create new intent with deterministic idempotency key
        # Generate deterministic key based on user_id, domain_name, hosting_plan_id, and service_type
        import hashlib
        deterministic_components = f"{user_id}|{domain_name or 'NULL'}|{hosting_plan_id}|{service_type}"
        deterministic_hash = hashlib.sha256(deterministic_components.encode()).hexdigest()[:16]
        idempotency_key = f"hosting_{deterministic_hash}"
        
        result = await execute_query(
            """INSERT INTO hosting_provision_intents 
               (user_id, domain_id, domain_name, hosting_plan_id, quote_price, currency, status, service_type, idempotency_key) 
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) 
               ON CONFLICT (idempotency_key) 
               DO UPDATE SET 
                   quote_price = EXCLUDED.quote_price,
                   domain_name = EXCLUDED.domain_name,
                   service_type = EXCLUDED.service_type,
                   updated_at = CURRENT_TIMESTAMP,
                   status = CASE 
                       WHEN hosting_provision_intents.status IN ('completed', 'failed') 
                       THEN 'pending_payment'
                       WHEN hosting_provision_intents.status IN ('pending', 'draft', 'awaiting_payment', 'pending_checkout', 'wallet_pending', 'payment_pending')
                       THEN 'pending_payment'
                       ELSE hosting_provision_intents.status 
                   END
               RETURNING id, status""",
            (user_id, domain_id, domain_name, hosting_plan_id, estimated_price, 'USD', 'pending_payment', service_type, idempotency_key)
        )
        
        if result:
            intent_id = result[0]['id']
            domain_info = f"domain '{domain_name}'" if domain_name else "no domain"
            logger.info(f"‚úÖ Created/updated hosting provision intent {intent_id} for {domain_info} by user {user_id}")
            return intent_id
        return None
        
    except Exception as e:
        domain_info = f"domain '{domain_name}'" if domain_name else "no domain"
        logger.error(f"‚ùå Error creating hosting provision intent for {domain_info}: {e}")
        return None

async def update_hosting_intent_status(intent_id: int, status: str, external_reference: Optional[str] = None, error_message: Optional[str] = None) -> bool:
    """Update hosting provision intent status"""
    try:
        if external_reference:
            await execute_update(
                """UPDATE hosting_provision_intents 
                   SET status = %s, external_reference = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, external_reference, intent_id)
            )
        elif error_message:
            await execute_update(
                """UPDATE hosting_provision_intents 
                   SET status = %s, last_error = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, error_message, intent_id)
            )
        else:
            await execute_update(
                """UPDATE hosting_provision_intents 
                   SET status = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, intent_id)
            )
        logger.info(f"‚úÖ Updated hosting intent {intent_id} status to {status}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating hosting intent {intent_id}: {e}")
        return False

async def finalize_hosting_provisioning(intent_id: int, cpanel_username: str, external_data: Dict[str, Any]) -> Union[bool, Dict[str, Any]]:
    """
    Finalize hosting provisioning by moving from intent to hosting_subscriptions table
    FIXED: Handles domain registration for bundles before hosting provisioning
    """
    from datetime import datetime, timedelta
    import json
    
    # First, check if this requires domain registration (outside transaction)
    try:
        intent_details = await execute_query(
            """SELECT user_id, domain_id, hosting_plan_id, quote_price, service_type, domain_name 
               FROM hosting_provision_intents WHERE id = %s""",
            (intent_id,)
        )
        
        if not intent_details:
            logger.error(f"‚ùå Hosting intent {intent_id} not found")
            return False
            
        intent = dict(intent_details[0])
        
        # Store bundle info for domain registration AFTER hosting subscription is created
        bundle_domain_registration_needed = (
            intent.get('service_type') == 'hosting_domain_bundle' 
            and intent.get('domain_name') 
            and not intent.get('domain_id')
        )
        if bundle_domain_registration_needed:
            logger.info(f"üåê Domain bundle detected - will register domain: {intent['domain_name']} after subscription creation")
    
    except Exception as e:
        logger.error(f"‚ùå Error checking intent details for {intent_id}: {e}")
        return False
    
    # Now proceed with hosting subscription creation in transaction
    def _finalize_in_transaction(conn, intent_id: int, cpanel_username: str, external_data: Dict[str, Any]) -> bool:
        """Execute finalization within a single transaction"""
        try:
            with conn.cursor() as cursor:
                # Get intent details with FOR UPDATE lock to prevent race conditions
                # This lock is now held for the entire transaction
                cursor.execute(
                    """SELECT user_id, domain_id, hosting_plan_id, quote_price, service_type, domain_name 
                       FROM hosting_provision_intents 
                       WHERE id = %s FOR UPDATE""",
                    (intent_id,)
                )
                intent_result = cursor.fetchone()
                
                if not intent_result:
                    logger.error(f"‚ùå Hosting intent {intent_id} not found for finalization")
                    return False
                    
                intent = dict(intent_result)
                
                # Check if hosting subscription already exists for this domain
                if intent['domain_id']:
                    cursor.execute(
                        "SELECT id FROM hosting_subscriptions WHERE domain_id = %s AND status = 'active'",
                        (intent['domain_id'],)
                    )
                    existing_hosting = cursor.fetchone()
                    
                    if existing_hosting:
                        logger.warning(f"‚ö†Ô∏è Active hosting subscription already exists for domain_id {intent['domain_id']}")
                        # Mark intent as completed with reference to existing subscription
                        cursor.execute(
                            """UPDATE hosting_provision_intents 
                               SET status = %s, external_reference = %s, updated_at = CURRENT_TIMESTAMP 
                               WHERE id = %s""",
                            ('completed', f"existing_subscription_{existing_hosting['id']}", intent_id)
                        )
                        return True
                
                # FIXED: Only mark as 'active' if cPanel account was actually created successfully
                # Check if external_data contains actual account creation success indicators
                cpanel_success = (
                    external_data.get('username') and 
                    external_data.get('password') and 
                    external_data.get('server_ip')
                )
                
                # SAGA PATTERN: Start with 'provisioning' status, only mark 'active' after ALL steps succeed
                subscription_status = 'provisioning' if cpanel_success else 'failed'
                
                logger.info(f"üìä Provisioning status: cPanel_success={cpanel_success}, status={subscription_status}")
                if not cpanel_success:
                    logger.warning(f"‚ö†Ô∏è cPanel account creation failed - marking subscription as 'failed'")
                    logger.warning(f"   Expected: username, password, server_ip")
                    logger.warning(f"   Received: {list(external_data.keys())}")
                
                # Fetch hosting plan data to get correct billing_cycle and duration_days
                cursor.execute(
                    "SELECT billing_cycle, duration_days FROM hosting_plans WHERE id = %s",
                    (intent['hosting_plan_id'],)
                )
                plan_result = cursor.fetchone()
                
                if plan_result:
                    billing_cycle = plan_result['billing_cycle']
                    duration_days = plan_result['duration_days']
                    logger.info(f"‚úÖ Using plan billing: {billing_cycle} ({duration_days} days) for plan {intent['hosting_plan_id']}")
                else:
                    logger.warning(f"‚ö†Ô∏è Could not fetch plan data for plan_id {intent['hosting_plan_id']}, defaulting to 'monthly' + 30 days")
                    billing_cycle = 'monthly'
                    duration_days = 30
                
                # Calculate next billing date using plan's actual duration
                next_billing_date = datetime.now() + timedelta(days=duration_days)
                
                # Create hosting subscription with proper foreign key relationship
                cursor.execute(
                    """INSERT INTO hosting_subscriptions 
                       (user_id, hosting_plan_id, domain_id, cpanel_username, cpanel_password, 
                        server_ip, status, billing_cycle, next_billing_date) 
                       VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) 
                       RETURNING id""",
                    (
                        intent['user_id'], 
                        intent['hosting_plan_id'], 
                        intent['domain_id'],
                        cpanel_username,
                        external_data.get('password'),
                        external_data.get('server_ip'),
                        subscription_status,  # Now correctly reflects actual provisioning status
                        billing_cycle,
                        next_billing_date
                    )
                )
                
                hosting_subscription_result = cursor.fetchone()
                if not hosting_subscription_result:
                    logger.error(f"‚ùå Failed to create hosting subscription for intent {intent_id}")
                    return False
                    
                subscription_id = hosting_subscription_result['id']
                
                # Create cPanel account record ONLY if provisioning was successful
                if cpanel_username and cpanel_success:
                    # Get domain name for cPanel account record
                    domain_name = None
                    if intent['domain_id']:
                        cursor.execute(
                            "SELECT domain_name FROM domains WHERE id = %s",
                            (intent['domain_id'],)
                        )
                        domain_result = cursor.fetchone()
                        if domain_result:
                            domain_name = domain_result['domain_name']
                    
                    cursor.execute(
                        """INSERT INTO cpanel_accounts 
                           (subscription_id, cpanel_username, cpanel_domain, 
                            server_name, ip_address, status) 
                           VALUES (%s, %s, %s, %s, %s, %s)""",
                        (
                            subscription_id,
                            cpanel_username,
                            domain_name,
                            external_data.get('server_name', 'server1'),
                            external_data.get('server_ip'),
                            'active'
                        )
                    )
                    logger.info(f"‚úÖ Created cPanel account record for {cpanel_username}")
                elif cpanel_username and not cpanel_success:
                    logger.warning(f"‚ö†Ô∏è Skipping cPanel account record creation - provisioning failed for {cpanel_username}")
                
                # Mark intent status based on actual provisioning success
                intent_status = 'completed' if cpanel_success else 'failed'
                cursor.execute(
                    """UPDATE hosting_provision_intents 
                       SET status = %s, external_reference = %s, updated_at = CURRENT_TIMESTAMP 
                       WHERE id = %s""",
                    (intent_status, f"subscription_{subscription_id}", intent_id)
                )
                
                domain_info = f"domain_id {intent['domain_id']}" if intent['domain_id'] else "no domain"
                if cpanel_success:
                    logger.info(f"‚úÖ Finalized hosting provisioning for {domain_info} - intent {intent_id}, subscription {subscription_id}")
                    return True
                else:
                    logger.error(f"‚ùå Hosting provisioning failed for {domain_info} - intent {intent_id}, subscription {subscription_id}")
                    return False
                
        except Exception as e:
            logger.error(f"‚ùå Error in transaction finalizing hosting provisioning for intent {intent_id}: {e}")
            return False
    
    # Execute the entire operation in a single transaction
    try:
        transaction_success = await run_in_transaction(_finalize_in_transaction, intent_id, cpanel_username, external_data)
        
        if transaction_success:
            # Handle different service types
            if bundle_domain_registration_needed:
                # Get the subscription_id from the completed intent
                subscription_result = await execute_query(
                    "SELECT external_reference FROM hosting_provision_intents WHERE id = %s",
                    (intent_id,)
                )
                
                if subscription_result and subscription_result[0]['external_reference'].startswith('subscription_'):
                    subscription_id = int(subscription_result[0]['external_reference'].replace('subscription_', ''))
                    
                    logger.info(f"üåê Registering domain {intent['domain_name']} for subscription {subscription_id}")
                    
                    # CRITICAL FIX: Avoid circular import by deferring domain registration
                    # Mark subscription for domain registration completion outside this function
                    logger.info(f"üåê Marking subscription {subscription_id} for domain registration: {intent['domain_name']}")
                    
                    # Return special status indicating domain registration is needed
                    # The calling code in handlers.py will handle domain registration
                    return {'success': True, 'needs_domain_registration': True, 'subscription_id': subscription_id, 'domain_name': intent['domain_name'], 'user_id': intent['user_id']}
            else:
                # Hosting-only subscription (no domain registration needed) - mark as active immediately
                subscription_result = await execute_query(
                    "SELECT external_reference FROM hosting_provision_intents WHERE id = %s",
                    (intent_id,)
                )
                
                if subscription_result and subscription_result[0]['external_reference'].startswith('subscription_'):
                    subscription_id = int(subscription_result[0]['external_reference'].replace('subscription_', ''))
                    
                    # Mark hosting-only subscription as active
                    await execute_update(
                        "UPDATE hosting_subscriptions SET status = 'active', updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (subscription_id,)
                    )
                    logger.info(f"‚úÖ Hosting-only subscription {subscription_id} marked as active")
        
        return transaction_success
        
    except Exception as e:
        logger.error(f"‚ùå Error finalizing hosting provisioning for intent {intent_id}: {e}")
        return False

async def _run_bundle_failure_compensation(subscription_id: int, domain_name: str) -> None:
    """
    Run compensating actions when domain registration fails in a hosting+domain bundle
    CRITICAL FIX: Prevents orphaned 'active' hosting subscriptions without domains
    """
    try:
        logger.info(f"üîÑ Running bundle failure compensation for subscription {subscription_id}, domain {domain_name}")
        
        # Step 1: Update hosting subscription to failed status
        await execute_update(
            "UPDATE hosting_subscriptions SET status = 'failed', updated_at = CURRENT_TIMESTAMP WHERE id = %s",
            (subscription_id,)
        )
        logger.info(f"‚úÖ Updated subscription {subscription_id} status to 'failed'")
        
        # Step 2: Clean up cPanel account records
        deleted_cpanel = await execute_update(
            "DELETE FROM cpanel_accounts WHERE subscription_id = %s",
            (subscription_id,)
        )
        if deleted_cpanel:
            logger.info(f"‚úÖ Cleaned up cPanel account for subscription {subscription_id}")
        
        # Step 3: Attempt Cloudflare zone cleanup using existing zone_id
        try:            
            # Try to find the zone_id for this domain in our database
            zone_query = await execute_query(
                "SELECT cf_zone_id FROM cloudflare_zones WHERE domain_name = %s",
                (domain_name,)
            )
            
            if zone_query:
                zone_id = zone_query[0]['cf_zone_id']
                logger.info(f"üóëÔ∏è Found Cloudflare zone {zone_id} for cleanup of {domain_name}")
                
                # Remove from our database - the zone will remain in Cloudflare for manual cleanup
                await execute_update(
                    "DELETE FROM cloudflare_zones WHERE domain_name = %s",
                    (domain_name,)
                )
                logger.info(f"‚úÖ Removed zone record from database for {domain_name}")
                logger.warning(f"‚ö†Ô∏è Manual Cloudflare zone cleanup needed for {domain_name} (zone_id: {zone_id})")
            else:
                logger.info(f"‚ÑπÔ∏è No Cloudflare zone found in database for {domain_name}")
                
        except Exception as cf_error:
            logger.warning(f"‚ö†Ô∏è Could not clean up Cloudflare zone for {domain_name}: {cf_error}")
        
        # Step 4: Get hosting subscription details for refund
        subscription_details = await execute_query(
            "SELECT user_id, hosting_plan_id FROM hosting_subscriptions WHERE id = %s",
            (subscription_id,)
        )
        
        if subscription_details:
            user_id = subscription_details[0]['user_id']
            
            # Get hosting plan price for refund calculation
            plan_details = await execute_query(
                "SELECT plan_price FROM hosting_plans WHERE id = %s",
                (subscription_details[0]['hosting_plan_id'],)
            )
            
            if plan_details:
                # This would refund the hosting portion, domain portion should be handled separately
                hosting_price = plan_details[0]['plan_price']
                logger.info(f"üí∞ Hosting portion to refund: ${hosting_price} for user {user_id}")
                # Note: Actual refund logic should be handled by the calling function
                # since it may involve bundle pricing that includes domain costs
        
        logger.info(f"‚úÖ Bundle failure compensation completed for subscription {subscription_id}")
        
    except Exception as e:
        logger.error(f"‚ùå Error running bundle failure compensation for subscription {subscription_id}: {e}")
        # Continue execution - compensation failures shouldn't block the main flow

async def get_active_hosting_intent(user_id: int, domain_name: Optional[str]) -> Optional[Dict]:
    """
    Check for active hosting provision intent for a domain by a user
    FIXED: Handles both existing domains (by domain_id) and new domains (by domain_name)
    """
    try:
        # Resolve domain_name to domain_id if provided
        domain_id = None
        if domain_name:
            domain_id = await get_domain_id_by_name(domain_name)
        
        # Search by both domain_id (for existing domains) and domain_name (for new domains)
        if domain_id:
            # Domain exists - search by domain_id
            result = await execute_query(
                """SELECT * FROM hosting_provision_intents 
                   WHERE user_id = %s AND domain_id = %s AND status IN ('pending_payment', 'provisioning', 'payment_confirmed', 'paid')
                   ORDER BY created_at DESC LIMIT 1""",
                (user_id, domain_id)
            )
        elif domain_name:
            # Domain doesn't exist yet (hosting bundle) - search by domain_name
            result = await execute_query(
                """SELECT * FROM hosting_provision_intents 
                   WHERE user_id = %s AND domain_name = %s AND domain_id IS NULL 
                   AND status IN ('pending_payment', 'provisioning', 'payment_confirmed', 'paid')
                   ORDER BY created_at DESC LIMIT 1""",
                (user_id, domain_name)
            )
        else:
            # No domain specified
            result = await execute_query(
                """SELECT * FROM hosting_provision_intents 
                   WHERE user_id = %s AND domain_id IS NULL AND domain_name IS NULL 
                   AND status IN ('pending_payment', 'provisioning', 'payment_confirmed', 'paid')
                   ORDER BY created_at DESC LIMIT 1""",
                (user_id,)
            )
        
        return dict(result[0]) if result else None
    except Exception as e:
        domain_info = f"domain '{domain_name}'" if domain_name else "no domain"
        logger.error(f"‚ùå Error checking active hosting intent for {domain_info}: {e}")
        return None

async def get_hosting_intent_by_id(intent_id: int) -> Optional[Dict]:
    """Get hosting provision intent by ID"""
    try:
        result = await execute_query(
            "SELECT * FROM hosting_provision_intents WHERE id = %s",
            (intent_id,)
        )
        return dict(result[0]) if result else None
    except Exception as e:
        logger.error(f"‚ùå Error getting hosting intent {intent_id}: {e}")
        return None

async def cleanup_expired_hosting_intents() -> int:
    """Clean up expired hosting provision intents"""
    try:
        result = await execute_query(
            """DELETE FROM hosting_provision_intents 
               WHERE expires_at < CURRENT_TIMESTAMP 
               AND status NOT IN ('completed', 'provisioning') 
               RETURNING id""",
        )
        count = len(result) if result else 0
        if count > 0:
            logger.info(f"üßπ Cleaned up {count} expired hosting provision intents")
        return count
    except Exception as e:
        logger.error(f"‚ùå Error cleaning up expired hosting intents: {e}")
        return 0

async def get_domain_id_by_name(domain_name: str) -> Optional[int]:
    """Get domain ID by domain name for intent system"""
    try:
        result = await execute_query(
            "SELECT id FROM domains WHERE domain_name = %s",
            (domain_name,)
        )
        return result[0]['id'] if result else None
    except Exception as e:
        logger.error(f"‚ùå Error getting domain ID for {domain_name}: {e}")
        return None


# ====================================================================
# PAYMENT INTENTS - PREVENT DUPLICATE PAYMENT ADDRESS CREATION
# ====================================================================

async def create_payment_intent(order_id: str, user_id: int, amount: float, currency: str = 'USD', crypto_currency: Optional[str] = None, provider: str = 'dynopay') -> Optional[int]:
    """
    Create payment intent to prevent duplicate payment address creation
    Uses order_id as natural idempotency key to prevent duplicates
    """
    try:
        import uuid
        idempotency_key = str(uuid.uuid4())
        
        # Try to insert new payment intent
        result = await execute_query(
            """INSERT INTO payment_intents 
               (order_id, user_id, amount, currency, crypto_currency, provider, status, idempotency_key) 
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s) 
               ON CONFLICT (order_id) DO NOTHING 
               RETURNING id""",
            (order_id, user_id, amount, currency, crypto_currency, provider, 'created', idempotency_key)
        )
        
        if result:
            intent_id = result[0]['id']
            logger.info(f"‚úÖ Created payment intent {intent_id} for order {order_id} by user {user_id}")
            return intent_id
        else:
            # Intent already exists, get existing intent
            existing_result = await execute_query(
                "SELECT id FROM payment_intents WHERE order_id = %s",
                (order_id,)
            )
            if existing_result:
                existing_intent_id = existing_result[0]['id']
                logger.info(f"‚ÑπÔ∏è Payment intent already exists for order {order_id}: intent {existing_intent_id}")
                return existing_intent_id
        
        return None
    except Exception as e:
        logger.error(f"‚ùå Error creating payment intent for order {order_id}: {e}")
        return None

async def get_payment_intent_by_order_id(order_id: str) -> Optional[Dict]:
    """Get payment intent by order ID"""
    try:
        result = await execute_query(
            "SELECT * FROM payment_intents WHERE order_id = %s",
            (order_id,)
        )
        return dict(result[0]) if result else None
    except Exception as e:
        logger.error(f"‚ùå Error getting payment intent for order {order_id}: {e}")
        return None

async def get_payment_intent_by_id(intent_id: int) -> Optional[Dict]:
    """Get payment intent by ID"""
    try:
        result = await execute_query(
            "SELECT * FROM payment_intents WHERE id = %s",
            (intent_id,)
        )
        return dict(result[0]) if result else None
    except Exception as e:
        logger.error(f"‚ùå Error getting payment intent {intent_id}: {e}")
        return None

async def update_payment_intent_status(intent_id: int, status: str, payment_address: Optional[str] = None, 
                                     payment_provider: Optional[str] = None, payment_provider_order_id: Optional[str] = None) -> bool:
    """Update payment intent status and details"""
    try:
        if payment_address and payment_provider:
            await execute_update(
                """UPDATE payment_intents 
                   SET status = %s, payment_address = %s, provider = %s, 
                       external_id = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, payment_address, payment_provider, payment_provider_order_id, intent_id)
            )
        elif payment_address:
            await execute_update(
                """UPDATE payment_intents 
                   SET status = %s, payment_address = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, payment_address, intent_id)
            )
        else:
            await execute_update(
                """UPDATE payment_intents 
                   SET status = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (status, intent_id)
            )
        logger.info(f"‚úÖ Updated payment intent {intent_id} status to {status}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error updating payment intent {intent_id}: {e}")
        return False

async def get_active_payment_intent(user_id: int, order_id: str) -> Optional[Dict]:
    """Get active payment intent for order"""
    try:
        result = await execute_query(
            """SELECT * FROM payment_intents 
               WHERE user_id = %s AND order_id = %s AND status NOT IN ('completed', 'expired') 
               ORDER BY created_at DESC LIMIT 1""",
            (user_id, order_id)
        )
        return dict(result[0]) if result else None
    except Exception as e:
        logger.error(f"‚ùå Error checking active payment intent for order {order_id}: {e}")
        return None

# CRITICAL: Atomic intent claiming functions for concurrency safety
async def claim_intent_for_address_creation(intent_id: int, provider_name: str, idempotency_key: str) -> Optional[Dict]:
    """
    Atomically claim payment intent for address creation using Compare-And-Swap (CAS) pattern
    Only one process can successfully claim an intent - prevents concurrent address creation
    
    Returns:
        Dict with intent data if successfully claimed, None if already claimed by another process
    """
    try:
        # Step 1: Atomically claim the intent using CAS pattern
        result = await execute_query(
            """UPDATE payment_intents 
               SET status = 'creating_address', updated_at = CURRENT_TIMESTAMP 
               WHERE id = %s AND status IN ('created', 'pending') 
               RETURNING id, order_id, user_id, amount, currency, crypto_currency, idempotency_key""",
            (intent_id,)
        )
        
        if not result:
            # Intent already claimed or in wrong state
            logger.info(f"‚ö†Ô∏è Intent {intent_id} already claimed or not available for address creation")
            return None
            
        intent_data = dict(result[0])
        logger.info(f"üîí Successfully claimed intent {intent_id} for address creation")
        
        # Step 2: Create provider claim record to prevent duplicate external calls
        try:
            await execute_update(
                """INSERT INTO provider_claims 
                   (order_id, provider_name, intent_id, idempotency_key, status) 
                   VALUES (%s, %s, %s, %s, 'claiming')""",
                (intent_data['order_id'], provider_name, intent_id, idempotency_key)
            )
            logger.info(f"üîí Created provider claim for {provider_name} on intent {intent_id}")
        except Exception as claim_error:
            # If provider claim fails, rollback intent status
            await execute_update(
                "UPDATE payment_intents SET status = 'created' WHERE id = %s",
                (intent_id,)
            )
            if "duplicate key" in str(claim_error).lower():
                logger.warning(f"‚ö†Ô∏è Provider {provider_name} already claimed intent {intent_id}")
                return None
            else:
                logger.error(f"‚ùå Failed to create provider claim: {claim_error}")
                raise claim_error
        
        return intent_data
        
    except Exception as e:
        logger.error(f"‚ùå Error claiming intent {intent_id}: {e}")
        return None

async def release_intent_claim(intent_id: int, provider_name: str, success: bool, payment_address: Optional[str] = None, external_order_id: Optional[str] = None) -> bool:
    """
    Release intent claim after address creation attempt
    
    Args:
        intent_id: Payment intent ID
        provider_name: Provider that made the claim
        success: Whether address creation was successful
        payment_address: Created payment address (if successful)
        external_order_id: External provider order ID (if successful)
    """
    try:
        if success and payment_address:
            # Mark intent as successfully completed
            await execute_update(
                """UPDATE payment_intents 
                   SET status = 'address_created', payment_address = %s, 
                       provider = %s, external_id = %s, 
                       updated_at = CURRENT_TIMESTAMP 
                   WHERE id = %s""",
                (payment_address, provider_name, external_order_id, intent_id)
            )
            
            # Update provider claim as successful
            await execute_update(
                """UPDATE provider_claims 
                   SET status = 'completed', external_address = %s, 
                       external_order_id = %s, updated_at = CURRENT_TIMESTAMP 
                   WHERE intent_id = %s AND provider_name = %s""",
                (payment_address, external_order_id, intent_id, provider_name)
            )
            
            logger.info(f"‚úÖ Successfully released intent {intent_id} claim with address {payment_address}")
        else:
            # Mark intent as failed and release claim
            await execute_update(
                "UPDATE payment_intents SET status = 'failed', updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                (intent_id,)
            )
            
            await execute_update(
                """UPDATE provider_claims 
                   SET status = 'failed', updated_at = CURRENT_TIMESTAMP 
                   WHERE intent_id = %s AND provider_name = %s""",
                (intent_id, provider_name)
            )
            
            logger.info(f"‚ö†Ô∏è Released intent {intent_id} claim due to failure")
            
        return True
    except Exception as e:
        logger.error(f"‚ùå Error releasing intent claim {intent_id}: {e}")
        return False

async def wait_for_intent_address_creation(intent_id: int, max_wait_seconds: int = 30) -> Optional[Dict]:
    """
    Wait for intent address creation to complete by another process
    Used when an intent is already claimed but we need the result
    
    Returns:
        Dict with intent data including payment_address if successful, None if timeout or failed
    """
    import asyncio
    
    start_time = time.time()
    wait_interval = 0.5  # 500ms polling interval
    
    logger.info(f"‚è∞ Waiting for intent {intent_id} address creation to complete...")
    
    while (time.time() - start_time) < max_wait_seconds:
        try:
            intent = await get_payment_intent_by_id(intent_id)
            if not intent:
                logger.error(f"‚ùå Intent {intent_id} disappeared during wait")
                return None
                
            status = intent.get('status')
            
            if status == 'address_created' and intent.get('payment_address'):
                logger.info(f"‚úÖ Intent {intent_id} address creation completed by another process")
                return intent
            elif status in ['failed', 'expired']:
                logger.warning(f"‚ö†Ô∏è Intent {intent_id} failed during address creation")
                return None
            
            # Still creating, wait and retry
            await asyncio.sleep(wait_interval)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error while waiting for intent {intent_id}: {e}")
            await asyncio.sleep(wait_interval)
    
    logger.warning(f"‚è∞ Timeout waiting for intent {intent_id} address creation")
    return None

async def finalize_payment_intent(intent_id: int, transaction_data: Dict[str, Any]) -> bool:
    """Finalize payment intent and mark as completed"""
    try:
        await execute_update(
            """UPDATE payment_intents 
               SET status = %s, updated_at = CURRENT_TIMESTAMP 
               WHERE id = %s""",
            ('completed', intent_id)
        )
        logger.info(f"‚úÖ Finalized payment intent {intent_id}")
        return True
    except Exception as e:
        logger.error(f"‚ùå Error finalizing payment intent {intent_id}: {e}")
        return False

async def cleanup_expired_payment_intents() -> int:
    """Clean up expired payment intents"""
    try:
        result = await execute_query(
            """UPDATE payment_intents 
               SET status = 'expired', updated_at = CURRENT_TIMESTAMP 
               WHERE expires_at < CURRENT_TIMESTAMP 
               AND status NOT IN ('completed', 'expired') 
               RETURNING id""",
        )
        count = len(result) if result else 0
        if count > 0:
            logger.info(f"üßπ Marked {count} payment intents as expired")
        return count
    except Exception as e:
        logger.error(f"‚ùå Error cleaning up expired payment intents: {e}")
        return 0

# Enhanced wallet transaction function with stronger constraints
async def create_wallet_transaction_with_constraints(user_id: int, transaction_type: str, amount: float, currency: str, 
                                                   description: str, external_txid: str, provider: str = 'unknown') -> bool:
    """
    Create wallet transaction with enhanced constraint handling for idempotency
    Uses external_txid + provider combination to prevent duplicates
    """
    try:
        result = await execute_query(
            """INSERT INTO wallet_transactions 
               (user_id, transaction_type, amount, currency, status, description, external_txid, provider) 
               VALUES (%s, %s, %s, %s, %s, %s, %s, %s) 
               ON CONFLICT (external_txid, provider) DO NOTHING 
               RETURNING id""",
            (user_id, transaction_type, amount, currency, 'completed', description, external_txid, provider)
        )
        
        if result:
            transaction_id = result[0]['id']
            logger.info(f"‚úÖ CONSTRAINT-SAFE: Created new wallet transaction {transaction_id} for user {user_id}")
            return True
        else:
            logger.info(f"‚ÑπÔ∏è CONSTRAINT-SAFE: Wallet transaction already exists for {external_txid}:{provider}")
            return True  # Consider idempotent operation as success
            
    except Exception as e:
        logger.error(f"‚ùå Error creating wallet transaction with constraints: {e}")
        return False

# Removed atomic_wallet_credit_with_external_txid - replaced with unified credit_user_wallet()

async def get_user_id_from_telegram_id(telegram_id: int) -> Optional[int]:
    """
    Get database user_id from telegram_id
    Used for wallet operations that need the internal user_id
    """
    try:
        result = await execute_query(
            "SELECT id FROM users WHERE telegram_id = %s",
            (telegram_id,)
        )
        if result:
            return result[0]['id']
        return None
    except Exception as e:
        logger.error(f"‚ùå Error getting user_id from telegram_id {telegram_id}: {e}")
        return None

async def queue_user_notification_by_user_id(user_id: int, message: str, parse_mode: str = 'HTML') -> bool:
    """
    BOT-INDEPENDENT: Queue user notification without requiring bot loop
    This function works even during bot startup/restart periods
    
    Args:
        user_id: Database user_id (not telegram_id) 
        message: Message to send
        parse_mode: Message parse mode
        
    Returns:
        bool: True if message was queued successfully
    """
    try:
        # Import here to avoid circular imports
        from webhook_handler import queue_user_message
        
        # Queue the message using the existing message queue system
        await queue_user_message(user_id, message, parse_mode)
        logger.info(f"‚úÖ BOT-INDEPENDENT: Notification queued for user_id {user_id}")
        return True
        
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è BOT-INDEPENDENT: Failed to queue notification for user_id {user_id}: {e}")
        return False

# Enhanced webhook callback registration with payment intent integration
async def register_webhook_with_payment_intent(order_id: str, confirmation_count: int, callback_type: str, 
                                              txid: Optional[str] = None, amount_usd: Optional[float] = None,
                                              provider: Optional[str] = None) -> Tuple[bool, Optional[Dict]]:
    """
    Register webhook callback and return associated payment intent if exists
    Returns: (is_new_callback, payment_intent_data)
    """
    # First register the webhook callback
    is_new = await register_webhook_callback(order_id, confirmation_count, callback_type, txid, amount_usd, provider)
    
    # Get payment intent if available
    payment_intent = await get_payment_intent_by_order_id(order_id)
    
    return (is_new, payment_intent)


# Cloudflare zone management
async def save_cloudflare_zone(domain_name: str, cf_zone_id: str, nameservers: List[str], status: str = 'active') -> bool:
    """Save Cloudflare zone information"""
    try:
        await execute_update(
            "INSERT INTO cloudflare_zones (domain_name, cf_zone_id, nameservers, status) VALUES (%s, %s, %s, %s)",
            (domain_name, cf_zone_id, nameservers, status)
        )
        return True
    except Exception as e:
        logger.error(f"Error saving Cloudflare zone: {e}")
        return False

async def get_cloudflare_zone(domain_name: str) -> Optional[Dict]:
    """Get Cloudflare zone information for a domain"""
    zones = await execute_query("SELECT * FROM cloudflare_zones WHERE domain_name = %s", (domain_name,))
    return dict(zones[0]) if zones else None

# Hosting management functions
async def get_hosting_plans() -> List[Dict]:
    """Get all active hosting plans"""
    return await execute_query("SELECT * FROM hosting_plans WHERE is_active = true ORDER BY monthly_price ASC")

async def get_hosting_plan(plan_id: int) -> Optional[Dict]:
    """Get specific hosting plan by ID"""
    plans = await execute_query("SELECT * FROM hosting_plans WHERE id = %s", (plan_id,))
    return dict(plans[0]) if plans else None

async def create_hosting_subscription(user_id: int, plan_id: int, domain_name: str, billing_cycle: Optional[str] = None) -> bool:
    """Create a new hosting subscription"""
    try:
        # If billing_cycle not provided, fetch from plan data
        if billing_cycle is None:
            plan_data = await get_hosting_plan(plan_id)
            if plan_data:
                billing_cycle = plan_data.get('billing_cycle', 'monthly')
                logger.info(f"‚úÖ Using plan billing cycle: {billing_cycle} for plan {plan_id}")
            else:
                logger.warning(f"‚ö†Ô∏è Could not fetch plan data for plan_id {plan_id}, defaulting to 'monthly'")
                billing_cycle = 'monthly'
        
        await execute_update(
            "INSERT INTO hosting_subscriptions (user_id, hosting_plan_id, domain_name, billing_cycle, status) VALUES (%s, %s, %s, %s, %s)",
            (user_id, plan_id, domain_name, billing_cycle, 'pending')
        )
        return True
    except Exception as e:
        logger.error(f"Error creating hosting subscription: {e}")
        return False

async def create_hosting_subscription_with_id(user_id: int, plan_id: int, domain_name: str, billing_cycle: Optional[str] = None) -> Optional[int]:
    """Create a new hosting subscription and return the subscription ID"""
    try:
        # If billing_cycle not provided, fetch from plan data
        if billing_cycle is None:
            plan_data = await get_hosting_plan(plan_id)
            if plan_data:
                billing_cycle = plan_data.get('billing_cycle', 'monthly')
                logger.info(f"‚úÖ Using plan billing cycle: {billing_cycle} for plan {plan_id}")
            else:
                logger.warning(f"‚ö†Ô∏è Could not fetch plan data for plan_id {plan_id}, defaulting to 'monthly'")
                billing_cycle = 'monthly'
        
        result = await execute_query(
            "INSERT INTO hosting_subscriptions (user_id, hosting_plan_id, domain_name, billing_cycle, status) VALUES (%s, %s, %s, %s, %s) RETURNING id",
            (user_id, plan_id, domain_name, billing_cycle, 'pending')
        )
        if result:
            return result[0]['id']
        return None
    except Exception as e:
        logger.error(f"Error creating hosting subscription with ID: {e}")
        return None

async def get_user_hosting_subscriptions(user_id: int) -> List[Dict]:
    """Get active hosting subscriptions for a user - FIXED: Only returns truly active plans"""
    return await execute_query("""
        SELECT hs.*, hp.plan_name, hp.plan_type, hp.monthly_price, hp.yearly_price 
        FROM hosting_subscriptions hs 
        JOIN hosting_plans hp ON hs.hosting_plan_id = hp.id 
        WHERE hs.user_id = %s 
        AND hs.status IN ('active', 'pending_renewal', 'grace_period')
        ORDER BY hs.created_at DESC
    """, (user_id,))

async def get_hosting_subscription_details(subscription_id: int, user_id: int) -> Optional[Dict]:
    """Get detailed hosting subscription information for a specific user"""
    results = await execute_query("""
        SELECT hs.*, hp.plan_name, hp.plan_type, hp.monthly_price, hp.yearly_price,
               ca.cpanel_username, ca.cpanel_domain, ca.server_name, ca.ip_address
        FROM hosting_subscriptions hs 
        JOIN hosting_plans hp ON hs.hosting_plan_id = hp.id 
        LEFT JOIN cpanel_accounts ca ON hs.id = ca.subscription_id
        WHERE hs.id = %s AND hs.user_id = %s
    """, (subscription_id, user_id))
    
    return results[0] if results else None

async def get_hosting_subscription_details_admin(subscription_id: int) -> Optional[Dict]:
    """Get detailed hosting subscription information (admin access - no user validation)"""
    try:
        results = await execute_query("""
            SELECT hs.*, hp.plan_name, hp.plan_type, hp.monthly_price, hp.yearly_price,
                   ca.cpanel_username, ca.cpanel_domain, ca.server_name, ca.ip_address
            FROM hosting_subscriptions hs 
            JOIN hosting_plans hp ON hs.hosting_plan_id = hp.id 
            LEFT JOIN cpanel_accounts ca ON hs.id = ca.subscription_id
            WHERE hs.id = %s
        """, (subscription_id,))
        
        return results[0] if results else None
    except Exception as e:
        logger.error(f"Error getting hosting subscription details (admin): {e}")
        return None

async def update_hosting_subscription_status(subscription_id: int, status: str) -> bool:
    """Update hosting subscription status"""
    try:
        await execute_update(
            "UPDATE hosting_subscriptions SET status = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
            (status, subscription_id)
        )
        return True
    except Exception as e:
        logger.error(f"Error updating hosting subscription status: {e}")
        return False

async def create_cpanel_account(subscription_id: int, username: str, domain: str, server_name: str, ip_address: str) -> bool:
    """Create cPanel account record"""
    try:
        await execute_update(
            "INSERT INTO cpanel_accounts (subscription_id, cpanel_username, cpanel_domain, server_name, ip_address, status) VALUES (%s, %s, %s, %s, %s, %s)",
            (subscription_id, username, domain, server_name, ip_address, 'active')
        )
        return True
    except Exception as e:
        logger.error(f"Error creating cPanel account: {e}")
        return False

# Wallet balance management functions
async def get_user_wallet_balance(telegram_id: int) -> float:
    """Get user's current wallet balance by telegram_id"""
    try:
        result = await execute_query("SELECT wallet_balance FROM users WHERE telegram_id = %s", (telegram_id,))
        if result:
            return float(result[0]['wallet_balance'] or 0.00)
        return 0.00
    except Exception as e:
        logger.error(f"Error getting wallet balance: {e}")
        return 0.00

async def get_user_wallet_balance_by_id(user_id: int) -> float:
    """Get user's current wallet balance by internal user_id (for testing)"""
    try:
        result = await execute_query("SELECT wallet_balance FROM users WHERE id = %s", (user_id,))
        if result:
            return float(result[0]['wallet_balance'] or 0.00)
        return 0.00
    except Exception as e:
        logger.error(f"Error getting wallet balance by user_id: {e}")
        return 0.00

async def update_wallet_balance(user_id: int, amount: float, transaction_type: str, description: str = '') -> bool:
    """Update user wallet balance and record transaction with atomic protection"""
    import psycopg2
    
    def _atomic_update() -> bool:
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # SECURITY: Row-level lock to prevent race conditions
                cursor.execute(
                    "SELECT id, wallet_balance FROM users WHERE id = %s FOR UPDATE",
                    (user_id,)
                )
                user_row = cast(Optional[RealDictRow], cursor.fetchone())
                if not user_row:
                    logger.error(f"User {user_id} not found for wallet update")
                    conn.rollback()
                    return False
                
                current_balance = float(user_row['wallet_balance'] or 0.00)
                new_balance = current_balance + amount
                
                # CRITICAL: Prevent negative balance for debits
                if new_balance < 0:
                    logger.warning(f"üö´ NEGATIVE BALANCE PROTECTION: User {user_id} insufficient balance: {current_balance} + {amount} = {new_balance}")
                    conn.rollback()
                    return False
                
                # Validate amount bounds
                if abs(amount) > 999999.99:
                    logger.error(f"üö´ AMOUNT VALIDATION: Amount too large for user {user_id}: {amount}")
                    conn.rollback()
                    return False
                
                # Update user balance atomically
                cursor.execute(
                    "UPDATE users SET wallet_balance = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (new_balance, user_id)
                )
                
                # Record transaction in same atomic transaction
                cursor.execute(
                    "INSERT INTO wallet_transactions (user_id, transaction_type, amount, currency, status, description) VALUES (%s, %s, %s, %s, %s, %s)",
                    (user_id, transaction_type, amount, 'USD', 'completed', description)
                )
                
                # Commit atomic transaction
                conn.commit()
                logger.info(f"‚úÖ ATOMIC WALLET UPDATE: User {user_id}, {transaction_type} {amount} USD, New balance: {new_balance}")
                return True
                
        except psycopg2.IntegrityError as e:
            if conn:
                conn.rollback()
            if "wallet_balance_non_negative" in str(e):
                logger.error(f"üö´ DATABASE CONSTRAINT: Negative balance prevented by DB constraint for user {user_id}")
            else:
                logger.error(f"Database integrity error in wallet update: {e}")
            return False
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Error in atomic wallet update: {e}")
            return False
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_update)

async def debit_wallet_balance(user_id: int, amount: float, description: str = '') -> bool:
    """
    BULLETPROOF debit operation with atomic transaction and comprehensive protection
    
    CRITICAL SECURITY FEATURES:
    - Atomic transaction with explicit row locking
    - Multiple validation layers preventing negative balances
    - Database constraint backup protection
    - Comprehensive audit logging
    """
    import psycopg2
    
    # Input validation - First line of defense
    if amount <= 0:
        logger.error(f"üö´ DEBIT VALIDATION: Invalid debit amount for user {user_id}: {amount}")
        return False
    
    if amount > 999999.99:
        logger.error(f"üö´ DEBIT VALIDATION: Debit amount too large for user {user_id}: {amount}")
        return False
    
    def _atomic_debit() -> bool:
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Use explicit transaction control
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # SECURITY: Lock user row to prevent race conditions
                cursor.execute(
                    "SELECT id, wallet_balance FROM users WHERE id = %s FOR UPDATE",
                    (user_id,)
                )
                user_row = cast(Optional[RealDictRow], cursor.fetchone())
                if not user_row:
                    logger.error(f"üö´ DEBIT ERROR: User {user_id} not found")
                    conn.rollback()
                    return False
                
                current_balance = float(user_row['wallet_balance'] or 0.00)
                new_balance = current_balance - amount
                
                # CRITICAL: Multiple negative balance checks
                if current_balance < amount:
                    logger.warning(f"üö´ DEBIT PROTECTION: User {user_id} insufficient balance: ${current_balance:.2f} < ${amount:.2f}")
                    conn.rollback()
                    return False
                
                if new_balance < 0:
                    logger.error(f"üö´ ATOMIC PROTECTION: Would create negative balance for user {user_id}: ${new_balance:.2f}")
                    conn.rollback()
                    return False
                
                # Update balance atomically
                cursor.execute(
                    "UPDATE users SET wallet_balance = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (new_balance, user_id)
                )
                
                # Record transaction
                cursor.execute(
                    "INSERT INTO wallet_transactions (user_id, transaction_type, amount, currency, status, description) VALUES (%s, %s, %s, %s, %s, %s)",
                    (user_id, 'debit', -amount, 'USD', 'completed', description)
                )
                
                # COMMIT: All operations succeeded
                conn.commit()
                # Enhanced balance tracking with Old ‚Üí New format for comprehensive audit trail
                logger.info(f"‚úÖ DEBIT SUCCESS: ${amount:.2f} debited from user {user_id} | Old: ${current_balance:.2f} ‚Üí New: ${new_balance:.2f} | Description: {description}")
                return True
                
        except psycopg2.IntegrityError as e:
            if conn:
                conn.rollback()
            if "wallet_balance_non_negative" in str(e):
                logger.error(f"üö´ DATABASE CONSTRAINT: Negative balance prevented by DB constraint for user {user_id}")
            else:
                logger.error(f"üö´ DATABASE INTEGRITY ERROR: {e}")
            return False
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"üö´ DEBIT ERROR: Atomic debit failed for user {user_id}: {e}")
            return False
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_debit)

async def atomic_wallet_credit_with_txid(user_id: int, amount: float, description: str, txid: str, deposit_order_id: str, confirmations: int, crypto_amount: str) -> bool:
    """Atomically credit wallet and update deposit status with txid protection"""
    def _atomic_credit():
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # 1. CRITICAL SECURITY: Row-level lock to prevent TOCTOU race conditions
                cursor.execute(
                    "SELECT id, status FROM wallet_deposits WHERE user_id = %s AND blockbee_order_id = %s FOR UPDATE",
                    (user_id, deposit_order_id)
                )
                deposit_row = cursor.fetchone()
                if not deposit_row:
                    logger.error(f"Deposit row not found for atomic operation: {deposit_order_id}")
                    conn.rollback()
                    return False
                
                # 2. Check txid idempotency within transaction
                cursor.execute("SELECT id, status FROM wallet_deposits WHERE txid = %s", (txid,))
                existing_txid = cursor.fetchone()
                if existing_txid:
                    logger.warning(f"üö´ ATOMIC PROTECTION: Transaction {txid[:16]}... already processed atomically")
                    conn.rollback()
                    return False
                
                # 3. Credit wallet balance
                cursor.execute("SELECT wallet_balance FROM users WHERE id = %s", (user_id,))
                user_result = cursor.fetchone()
                if not user_result:
                    logger.error(f"User {user_id} not found for wallet credit")
                    conn.rollback()
                    return False
                
                if not user_result:
                    logger.error(f"User {user_id} not found for wallet credit")
                    conn.rollback()
                    return False
                current_balance = float(cast(Dict[str, Any], user_result)['wallet_balance'] or 0)
                new_balance = current_balance + amount
                
                cursor.execute(
                    "UPDATE users SET wallet_balance = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (new_balance, user_id)
                )
                
                # 4. Record transaction
                cursor.execute(
                    "INSERT INTO wallet_transactions (user_id, transaction_type, amount, currency, status, description) VALUES (%s, %s, %s, %s, %s, %s)",
                    (user_id, 'credit', amount, 'USD', 'completed', description)
                )
                
                # 5. Update deposit status with txid atomically
                cursor.execute(
                    "UPDATE wallet_deposits SET status = %s, confirmations = %s, crypto_amount = %s, txid = %s, updated_at = CURRENT_TIMESTAMP WHERE blockbee_order_id = %s",
                    ('completed', confirmations, crypto_amount, txid, deposit_order_id)
                )
                
                # 6. Clean up authentication token now that payment is finalized
                cursor.execute(
                    "DELETE FROM callback_tokens WHERE callback_data = %s AND user_id = %s",
                    (f"order_id:{deposit_order_id}", user_id)
                )
                token_deleted = cursor.rowcount
                
                # COMMIT: All operations succeeded
                conn.commit()
                logger.info(f"‚úÖ ATOMIC: Wallet credited ${amount} to user {user_id}, txid: {txid[:16]}..., token cleaned: {token_deleted > 0}")
                return True
                
        except Exception as e:
            if conn:
                try:
                    conn.rollback()
                    logger.error(f"‚ùå ATOMIC ROLLBACK: Wallet credit failed, rolled back: {e}")
                except:
                    logger.error(f"‚ùå CRITICAL: Rollback failed: {e}")
            return False
        finally:
            if conn:
                # Restore autocommit and return connection
                conn.autocommit = True
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_credit)

async def atomic_domain_order_confirm_with_txid(user_id: int, expected_usd: float, received_usd: float, txid: str, order_id: str, confirmations: int, crypto_amount: str) -> bool:
    """Atomically confirm domain order with strict amount validation and txid protection"""
    def _atomic_confirm():
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # 1. CRITICAL SECURITY: Row-level lock to prevent TOCTOU race conditions
                cursor.execute(
                    "SELECT id, status FROM domain_orders WHERE blockbee_order_id = %s FOR UPDATE",
                    (order_id,)
                )
                order_row = cursor.fetchone()
                if not order_row:
                    logger.error(f"Domain order not found for atomic operation: {order_id}")
                    conn.rollback()
                    return False
                
                # 2. Check txid idempotency within transaction
                cursor.execute("SELECT id, status FROM domain_orders WHERE txid = %s", (txid,))
                existing_txid = cursor.fetchone()
                if existing_txid:
                    logger.warning(f"üö´ ATOMIC PROTECTION: Domain transaction {txid[:16]}... already processed atomically")
                    conn.rollback()
                    return False
                
                # 3. UNIFIED VALIDATION: Use same tolerance logic as webhook handler
                is_payment_valid = validate_payment_simple(expected_usd, received_usd, 'domain_order', 'database')
                if not is_payment_valid:
                    logger.warning(f"üö´ UNIFIED VALIDATION: Domain order payment rejected - received ${received_usd}, expected ${expected_usd}")
                    # Update order with failed status
                    cursor.execute(
                        "UPDATE domain_orders SET status = %s, confirmations = %s, txid = %s, updated_at = CURRENT_TIMESTAMP WHERE blockbee_order_id = %s",
                        ('insufficient_amount', confirmations, txid, order_id)
                    )
                    conn.commit()
                    return False
                else:
                    logger.info(f"‚úÖ UNIFIED VALIDATION: Domain order payment accepted - received ${received_usd}, expected ${expected_usd}")
                
                # 4. Update domain order status to confirmed
                cursor.execute(
                    "UPDATE domain_orders SET status = %s, confirmations = %s, txid = %s, updated_at = CURRENT_TIMESTAMP WHERE blockbee_order_id = %s",
                    ('payment_confirmed', confirmations, txid, order_id)
                )
                
                # 5. Clean up authentication token now that payment is finalized
                cursor.execute(
                    "DELETE FROM callback_tokens WHERE callback_data = %s AND user_id = %s",
                    (f"order_id:{order_id}", user_id)
                )
                token_deleted = cursor.rowcount
                
                # COMMIT: All operations succeeded
                conn.commit()
                logger.info(f"‚úÖ ATOMIC: Domain order confirmed, txid: {txid[:16]}..., token cleaned: {token_deleted > 0}")
                return True
                
        except Exception as e:
            if conn:
                try:
                    conn.rollback()
                    logger.error(f"‚ùå ATOMIC ROLLBACK: Domain order confirmation failed, rolled back: {e}")
                except:
                    logger.error(f"‚ùå CRITICAL: Rollback failed: {e}")
            return False
        finally:
            if conn:
                # Restore autocommit and return connection
                conn.autocommit = True
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_confirm)

async def atomic_domain_overpayment_credit_with_txid(user_id: int, overpayment_amount: float, domain_name: str, txid: str, order_id: str, external_txid: str) -> bool:
    """
    Atomically credit domain overpayment to user wallet with proper idempotency protection
    
    SECURITY FEATURES:
    - Proper external_txid-based idempotency (unique constraint enforcement)
    - Atomic balance update operation (no race conditions)
    - Full transactional integrity with proper rollback
    - Input validation for overpayment amount
    - Comprehensive audit logging
    
    Args:
        user_id: User ID to credit
        overpayment_amount: Amount of overpayment to credit to wallet (must be > 0)
        domain_name: Domain name for transaction description
        txid: Blockchain transaction ID for reference
        order_id: Domain order ID for reference
        external_txid: Unique external transaction ID for idempotency protection
        
    Returns:
        bool: True if credit was successful, False if failed or duplicate
    """
    import psycopg2
    
    def _atomic_overpayment_credit():
        conn = None
        try:
            # VALIDATION: Ensure overpayment amount is positive
            if overpayment_amount <= 0:
                logger.error(f"‚ùå VALIDATION ERROR: Invalid overpayment amount ${overpayment_amount:.4f} for user {user_id}")
                return False
                
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # 1. IDEMPOTENCY: Try to insert transaction record with unique external_txid
                # This provides atomic duplicate check via database unique constraint
                try:
                    cursor.execute(
                        """INSERT INTO wallet_transactions 
                           (user_id, transaction_type, amount, currency, status, external_txid, description)
                           VALUES (%s, %s, %s, %s, %s, %s, %s)""",
                        (
                            user_id, 
                            'credit', 
                            overpayment_amount, 
                            'USD', 
                            'completed', 
                            external_txid,
                            f"Domain overpayment credit: {domain_name} (order: {order_id}, txid: {txid[:8]}...)"
                        )
                    )
                    logger.info(f"üí≥ TRANSACTION RECORD: Overpayment transaction {external_txid} recorded")
                    
                except psycopg2.IntegrityError as e:
                    # Unique constraint violation - transaction already processed
                    conn.rollback()
                    if 'external_txid' in str(e).lower() or 'unique' in str(e).lower():
                        logger.warning(f"üö´ IDEMPOTENCY PROTECTION: Overpayment {external_txid} already processed (duplicate blocked)")
                        return False
                    else:
                        # Different integrity error - re-raise
                        logger.error(f"‚ùå DATABASE INTEGRITY ERROR: {e}")
                        raise
                
                # 2. ATOMIC BALANCE UPDATE: Use SQL arithmetic to prevent race conditions
                # This eliminates read-modify-write race conditions completely
                cursor.execute(
                    """UPDATE users 
                       SET wallet_balance = wallet_balance + %s, 
                           updated_at = CURRENT_TIMESTAMP 
                       WHERE id = %s
                       RETURNING wallet_balance""",
                    (overpayment_amount, user_id)
                )
                
                updated_user = cursor.fetchone()
                if not updated_user:
                    logger.error(f"‚ùå USER NOT FOUND: User {user_id} does not exist for overpayment credit")
                    conn.rollback()
                    return False
                new_balance = float(cast(Dict[str, Any], updated_user)['wallet_balance'])
                
                # COMMIT: All operations succeeded atomically
                conn.commit()
                
                # SUCCESS: Log comprehensive audit trail
                logger.info(f"‚úÖ OVERPAYMENT SUCCESS: Domain overpayment processed atomically")
                logger.info(f"   User: {user_id}")
                logger.info(f"   Domain: {domain_name}")
                logger.info(f"   Order: {order_id}")
                logger.info(f"   Amount: ${overpayment_amount:.4f} USD")
                logger.info(f"   New Balance: ${new_balance:.4f} USD")
                logger.info(f"   External TxID: {external_txid}")
                logger.info(f"   Blockchain TxID: {txid[:16]}...")
                
                return True
                
        except Exception as e:
            if conn:
                try:
                    conn.rollback()
                    logger.error(f"‚ùå OVERPAYMENT ROLLBACK: Domain overpayment credit failed and was rolled back")
                    logger.error(f"   Error: {e}")
                    logger.error(f"   External TxID: {external_txid}")
                    logger.error(f"   User: {user_id}, Amount: ${overpayment_amount:.4f}")
                except Exception as rollback_error:
                    logger.error(f"‚ùå CRITICAL ROLLBACK FAILURE: {rollback_error}")
            return False
        finally:
            if conn:
                # Restore autocommit and return connection
                conn.autocommit = True
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_overpayment_credit)

async def register_webhook_callback(order_id: str, confirmation_count: int, callback_type: str, txid: Optional[str] = None, amount_usd: Optional[float] = None, provider: Optional[str] = None, external_id: Optional[str] = None) -> bool:
    """
    Atomically register a webhook callback to prevent duplicate processing.
    Enhanced with provider and external_id for stronger idempotency protection.
    
    Args:
        order_id: BlockBee/DynoPay order ID
        confirmation_count: Number of confirmations
        callback_type: Type of callback ('wallet_deposit', 'domain_order', 'hosting_payment')
        txid: Optional transaction ID for tracking
        amount_usd: Optional USD amount for tracking
        provider: Optional payment provider name ('blockbee', 'dynopay')
        external_id: Optional provider-specific external identifier
        
    Returns:
        bool: True if callback is safe to process (new), False if duplicate
    """
    def _atomic_register():
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                try:
                    # Enhanced: Insert with provider_name and external_callback_id for stronger idempotency
                    cursor.execute(
                        """INSERT INTO webhook_callbacks 
                           (order_id, confirmation_count, callback_type, status, txid, amount_usd, provider_name, external_callback_id) 
                           VALUES (%s, %s, %s, %s, %s, %s, %s, %s)""",
                        (order_id, confirmation_count, callback_type, 'processing', txid, amount_usd, provider, external_id)
                    )
                    
                    # If we reach here, insertion succeeded - this is a new callback
                    conn.commit()
                    logger.info(f"‚úÖ WEBHOOK IDEMPOTENCY: New callback registered - {callback_type}:{order_id}:{confirmation_count}")
                    return True
                    
                except psycopg2.IntegrityError as e:
                    # Unique constraint violation - callback already exists
                    conn.rollback()
                    
                    # Check if existing callback is completed (within the same transaction context)
                    cursor.execute(
                        "SELECT status, completed_at FROM webhook_callbacks WHERE order_id = %s AND confirmation_count = %s AND callback_type = %s",
                        (order_id, confirmation_count, callback_type)
                    )
                    existing = cursor.fetchone()
                    
                    if existing:
                        existing_dict = cast(Dict[str, Any], existing)
                        status = str(existing_dict['status'])
                        completed_at = existing_dict['completed_at']
                        
                        if status == 'completed':
                            logger.info(f"üö´ WEBHOOK IDEMPOTENCY: Callback already completed - {callback_type}:{order_id}:{confirmation_count}")
                        elif status == 'failed':
                            logger.info(f"üö´ WEBHOOK IDEMPOTENCY: Callback already failed - {callback_type}:{order_id}:{confirmation_count}")
                        else:
                            logger.warning(f"üö´ WEBHOOK IDEMPOTENCY: Callback already processing - {callback_type}:{order_id}:{confirmation_count}")
                    else:
                        logger.warning(f"üö´ WEBHOOK IDEMPOTENCY: Duplicate callback detected - {callback_type}:{order_id}:{confirmation_count}")
                    
                    # Restore autocommit before returning
                    conn.autocommit = True
                    return False
                    
        except Exception as e:
            if conn:
                try:
                    conn.rollback()
                    conn.autocommit = True  # Restore autocommit after rollback
                except:
                    pass
            logger.error(f"‚ùå Error registering webhook callback: {e}")
            return False
        finally:
            if conn:
                # Ensure autocommit is restored and return connection
                try:
                    if not conn.autocommit:
                        conn.autocommit = True
                except:
                    pass
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_register)

async def complete_webhook_callback(order_id: str, confirmation_count: int, callback_type: str, success: bool = True) -> bool:
    """
    Mark a webhook callback as completed or failed.
    
    Args:
        order_id: BlockBee order ID
        confirmation_count: Number of confirmations
        callback_type: Type of callback ('wallet_deposit' or 'domain_order')
        success: Whether the callback processing was successful
        
    Returns:
        bool: True if status was updated successfully
    """
    try:
        status = 'completed' if success else 'failed'
        result = await execute_update(
            """UPDATE webhook_callbacks 
               SET status = %s, completed_at = CURRENT_TIMESTAMP 
               WHERE order_id = %s AND confirmation_count = %s AND callback_type = %s""",
            (status, order_id, confirmation_count, callback_type)
        )
        
        if result:
            logger.info(f"‚úÖ WEBHOOK IDEMPOTENCY: Callback marked as {status} - {callback_type}:{order_id}:{confirmation_count}")
            return True
        else:
            logger.warning(f"‚ö†Ô∏è WEBHOOK IDEMPOTENCY: No callback found to mark as {status} - {callback_type}:{order_id}:{confirmation_count}")
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error completing webhook callback: {e}")
        return False

async def cleanup_old_webhook_callbacks(days_old: int = 30) -> int:
    """
    Clean up old webhook callback records to prevent table bloat.
    
    Args:
        days_old: Delete records older than this many days
        
    Returns:
        int: Number of records deleted
    """
    try:
        result = await execute_update(
            """DELETE FROM webhook_callbacks 
               WHERE processed_at < NOW() - INTERVAL '%s days' 
               AND status IN ('completed', 'failed')""",
            (days_old,)
        )
        
        if result:
            logger.info(f"üßπ WEBHOOK CLEANUP: Deleted {result} old webhook callback records (>{days_old} days)")
        
        return result or 0
        
    except Exception as e:
        logger.error(f"‚ùå Error cleaning up webhook callbacks: {e}")
        return 0

# Removed credit_wallet_balance - replaced with unified credit_user_wallet()

async def credit_user_wallet(user_id: int, amount_usd: float, provider: str, txid: str, order_id: str) -> bool:
    """
    PRODUCTION: Fixed unified wallet credit function with enhanced reliability
    
    Features:
    - Strict boolean return type (never returns integers)
    - Robust type handling for Decimal/float conversions
    - Enhanced exception handling with detailed debugging
    - Single connection retry on connection failures
    - Structured logging with clear failure reasons
    - Duplicates treated as idempotent success (return True)
    - Explicit user existence validation
    - Database-level idempotency via UNIQUE(external_txid, provider)
    
    Args:
        user_id: Database user ID (not telegram_id)
        amount_usd: Amount to credit in USD
        provider: Payment provider ('dynopay', 'blockbee', etc.)
        txid: Transaction ID from provider
        order_id: Our internal order ID
        
    Returns:
        bool: True if credited successfully OR duplicate (idempotent), False only on actual failure
    """
    import psycopg2
    from decimal import Decimal, InvalidOperation
    
    # Enhanced input validation
    try:
        amount_usd = float(amount_usd)  # Ensure proper type
    except (TypeError, ValueError) as e:
        logger.error(f"‚ùå WALLET_CREDIT_TYPE_ERROR: Invalid amount_usd type: {type(amount_usd)} = {amount_usd} | Error: {e}")
        return False
    
    if amount_usd <= 0 or amount_usd > 50000:
        logger.error(f"‚ùå WALLET_CREDIT_VALIDATION_FAILED: Invalid amount ${amount_usd:.2f} for user {user_id} (valid range: $0.01-$50,000)")
        return False
    
    if not txid or not provider:
        logger.error(f"‚ùå WALLET_CREDIT_VALIDATION_FAILED: Missing required fields - txid='{txid}', provider='{provider}' for user {user_id}")
        return False
    
    # Security gate check
    if not os.getenv('FINANCIAL_OPERATIONS_ENABLED', 'true').lower() == 'true':
        logger.error(f"‚ùå WALLET_CREDIT_SECURITY_BLOCKED: Financial operations disabled by configuration")
        return False
    
    def safe_decimal_to_float(value, field_name: str) -> float:
        """Safely convert database Decimal/numeric values to float"""
        try:
            if value is None:
                return 0.0
            if isinstance(value, (int, float)):
                return float(value)
            if isinstance(value, Decimal):
                return float(value)
            if isinstance(value, str):
                return float(Decimal(value))
            # Fallback for other types
            return float(value)
        except (TypeError, ValueError, InvalidOperation) as e:
            logger.error(f"‚ùå WALLET_CREDIT_CONVERSION_ERROR: Failed to convert {field_name} value {value} (type: {type(value)}) to float: {e}")
            raise ValueError(f"Invalid {field_name} value: {value}")
    
    def _credit_wallet_with_retry():
        """Internal function with single bounded retry for connection failures only"""
        max_attempts = 2  # Original attempt + 1 retry for connection issues only
        
        for attempt in range(max_attempts):
            conn = None
            try:
                conn = get_connection()
                conn.autocommit = False
                
                with conn.cursor() as cursor:
                    # STEP 1: Explicit user existence validation with debugging
                    cursor.execute("SELECT id, wallet_balance FROM users WHERE id = %s", (user_id,))
                    user_result = cursor.fetchone()
                    if not user_result:
                        logger.error(f"‚ùå WALLET_CREDIT_USER_NOT_FOUND: user_id {user_id} does not exist in database")
                        conn.rollback()
                        return False
                    
                    # DEBUG: Log the actual result structure
                    logger.info(f"üîç WALLET_CREDIT_DEBUG: user_result type={type(user_result)}, content={user_result}")
                    
                    # Safe conversion with detailed debugging
                    try:
                        # Handle both tuple and dict-like access patterns with explicit typing
                        if hasattr(user_result, 'keys'):  # Dict-like (RealDictRow)
                            user_dict = cast(Any, user_result)  # Explicit cast to Any for dictionary access
                            current_balance = safe_decimal_to_float(user_dict['wallet_balance'], "wallet_balance")
                            user_db_id = user_dict['id']
                        else:  # Tuple-like
                            if len(user_result) < 2:
                                raise ValueError(f"Expected 2 columns, got {len(user_result)}: {user_result}")
                            current_balance = safe_decimal_to_float(user_result[1], "wallet_balance")
                            user_db_id = user_result[0]
                        
                        logger.info(f"üîç WALLET_CREDIT_USER_VALIDATED: user_id {user_id} (db_id: {user_db_id}) exists with current balance ${current_balance:.2f}")
                    except (ValueError, KeyError, IndexError) as conv_error:
                        logger.error(f"‚ùå WALLET_CREDIT_BALANCE_CONVERSION_ERROR: {conv_error} | user_result: {user_result}")
                        conn.rollback()
                        return False
                    
                    # STEP 2: Attempt transaction insert with idempotency check
                    try:
                        cursor.execute(
                            """INSERT INTO wallet_transactions 
                               (user_id, transaction_type, amount, currency, status, external_txid, provider, description)
                               VALUES (%s, 'credit', %s, 'USD', 'completed', %s, %s, %s)
                               ON CONFLICT (external_txid, provider) DO NOTHING
                               RETURNING id""",
                            (user_id, amount_usd, txid, provider, f"Payment {order_id}")
                        )
                    except Exception as insert_error:
                        logger.error(f"‚ùå WALLET_CREDIT_INSERT_ERROR: Failed to insert transaction | user_id: {user_id} | Error: {insert_error}")
                        conn.rollback()
                        return False
                    
                    transaction_result = cursor.fetchone()
                    if not transaction_result:
                        # DUPLICATE PAYMENT: Treat as idempotent success
                        logger.info(f"‚úÖ WALLET_CREDIT_DUPLICATE_SUCCESS: Payment {txid}:{provider} already processed - idempotent result for user {user_id}")
                        conn.rollback()
                        return True  # ARCHITECT FIX: Return True for duplicates (idempotent)
                    
                    # DEBUG: Log the actual transaction result structure
                    logger.info(f"üîç WALLET_CREDIT_DEBUG: transaction_result type={type(transaction_result)}, content={transaction_result}")
                    
                    try:
                        # Handle both tuple and dict-like access patterns for transaction ID with explicit typing
                        if hasattr(transaction_result, 'keys'):  # Dict-like (RealDictRow)
                            trans_dict = cast(Any, transaction_result)  # Explicit cast to Any for dictionary access
                            transaction_id = int(trans_dict['id'])
                        else:  # Tuple-like
                            if len(transaction_result) < 1:
                                raise ValueError(f"Expected at least 1 column, got {len(transaction_result)}: {transaction_result}")
                            transaction_id = int(transaction_result[0])
                        
                        logger.info(f"üí∞ WALLET_CREDIT_TRANSACTION_CREATED: transaction_id {transaction_id} for ${amount_usd:.2f}")
                    except (TypeError, ValueError, KeyError, IndexError) as id_error:
                        logger.error(f"‚ùå WALLET_CREDIT_ID_ERROR: Invalid transaction_id | Error: {id_error} | transaction_result: {transaction_result}")
                        conn.rollback()
                        return False
                    
                    # STEP 3: Credit wallet balance with explicit rowcount validation
                    try:
                        cursor.execute(
                            """UPDATE users 
                               SET wallet_balance = wallet_balance + %s, updated_at = CURRENT_TIMESTAMP 
                               WHERE id = %s
                               RETURNING wallet_balance""",
                            (amount_usd, user_id)
                        )
                        
                        # Explicit rowcount validation
                        if cursor.rowcount != 1:
                            logger.error(f"‚ùå WALLET_CREDIT_ROWCOUNT_ERROR: UPDATE affected {cursor.rowcount} rows (expected 1) for user_id {user_id}")
                            conn.rollback()
                            return False
                    except Exception as update_error:
                        logger.error(f"‚ùå WALLET_CREDIT_UPDATE_ERROR: Failed to update balance | user_id: {user_id} | Error: {update_error}")
                        conn.rollback()
                        return False
                    
                    balance_result = cursor.fetchone()
                    if not balance_result:
                        logger.error(f"‚ùå WALLET_CREDIT_UPDATE_FAILED: No balance returned after update for user_id {user_id}")
                        conn.rollback()
                        return False
                    
                    # DEBUG: Log the actual balance result structure
                    logger.info(f"üîç WALLET_CREDIT_DEBUG: balance_result type={type(balance_result)}, content={balance_result}")
                    
                    try:
                        # Handle both tuple and dict-like access patterns for balance with explicit typing
                        if hasattr(balance_result, 'keys'):  # Dict-like (RealDictRow)
                            balance_dict = cast(Any, balance_result)  # Explicit cast to Any for dictionary access
                            new_balance = safe_decimal_to_float(balance_dict['wallet_balance'], "new_wallet_balance")
                        else:  # Tuple-like
                            if len(balance_result) < 1:
                                raise ValueError(f"Expected at least 1 column, got {len(balance_result)}: {balance_result}")
                            new_balance = safe_decimal_to_float(balance_result[0], "new_wallet_balance")
                    except (ValueError, KeyError, IndexError) as balance_error:
                        logger.error(f"‚ùå WALLET_CREDIT_NEW_BALANCE_ERROR: {balance_error} | balance_result: {balance_result}")
                        conn.rollback()
                        return False
                    
                    # STEP 4: Commit transaction
                    try:
                        conn.commit()
                        logger.info(f"‚úÖ WALLET_CREDIT_SUCCESS: ${amount_usd:.2f} credited to user {user_id} | Old: ${current_balance:.2f} ‚Üí New: ${new_balance:.2f} | txid: {txid[:16]}... | transaction_id: {transaction_id}")
                        
                        # CRITICAL FIX: Invalidate user cache after successful wallet credit
                        # This ensures dashboard shows fresh balance instead of cached stale balance
                        try:
                            # Get telegram_id for cache invalidation (since cache uses telegram_id as key)
                            cursor.execute("SELECT telegram_id FROM users WHERE id = %s", (user_id,))
                            telegram_result = cursor.fetchone()
                            if telegram_result:
                                telegram_id = telegram_result[0] if isinstance(telegram_result, (tuple, list)) else telegram_result['telegram_id']
                                
                                from performance_cache import delete_cached
                                delete_cached(f'user_data_{telegram_id}')
                                logger.info(f"üîÑ CACHE_INVALIDATED: User cache cleared for telegram_id {telegram_id} after wallet credit")
                        except Exception as cache_error:
                            # Non-critical error - don't fail the wallet operation
                            logger.warning(f"‚ö†Ô∏è CACHE_INVALIDATION_WARNING: Failed to invalidate user cache after wallet credit: {cache_error}")
                        
                        return True  # ARCHITECT FIX: Guaranteed boolean return
                    except Exception as commit_error:
                        logger.error(f"‚ùå WALLET_CREDIT_COMMIT_ERROR: Failed to commit transaction | Error: {commit_error}")
                        conn.rollback()
                        return False
                    
            except (psycopg2.OperationalError, psycopg2.InterfaceError) as conn_error:
                # Connection-level errors that can be retried ONCE
                if conn:
                    try:
                        conn.rollback()
                    except:
                        pass
                    return_connection(conn, is_broken=True)
                    conn = None
                
                if attempt < max_attempts - 1:
                    logger.warning(f"‚ö†Ô∏è WALLET_CREDIT_CONNECTION_RETRY: Attempt {attempt + 1}/{max_attempts} failed - retrying once | Error: {str(conn_error)[:100]}")
                    continue
                else:
                    logger.error(f"‚ùå WALLET_CREDIT_CONNECTION_FAILURE: All {max_attempts} attempts failed | Final error: {conn_error}")
                    return False
                    
            except psycopg2.IntegrityError as integrity_error:
                # Database constraint violations (should not happen with our ON CONFLICT)
                if conn:
                    try:
                        conn.rollback()
                    except:
                        pass
                logger.error(f"‚ùå WALLET_CREDIT_INTEGRITY_ERROR: Database constraint violation | txid: {txid} | provider: {provider} | Error: {integrity_error}")
                return False
            
            except ValueError as value_error:
                # Type conversion errors (from safe_decimal_to_float)
                if conn:
                    try:
                        conn.rollback()
                    except:
                        pass
                logger.error(f"‚ùå WALLET_CREDIT_VALUE_ERROR: Type conversion failed | user_id: {user_id} | Error: {value_error}")
                return False
                
            except Exception as unexpected_error:
                # Other errors should not be retried - enhanced debugging
                if conn:
                    try:
                        conn.rollback()
                    except:
                        pass
                logger.error(f"‚ùå WALLET_CREDIT_UNEXPECTED_ERROR: user_id {user_id} | amount ${amount_usd:.2f} | txid {txid} | Error Type: {type(unexpected_error).__name__} | Error: {unexpected_error}")
                logger.error(f"‚ùå WALLET_CREDIT_ERROR_DETAILS: Error args: {getattr(unexpected_error, 'args', 'No args')}")
                return False
                
            finally:
                if conn:
                    try:
                        conn.autocommit = True
                        return_connection(conn)
                    except:
                        pass
        
        # Should never reach here due to explicit returns above
        logger.error(f"‚ùå WALLET_CREDIT_LOGIC_ERROR: Unexpected code path reached for user_id {user_id}")
        return False
    
    # Enhanced async handling with proper timeout and isolation
    try:
        # Use asyncio.wait_for for timeout protection
        result = await asyncio.wait_for(
            asyncio.to_thread(_credit_wallet_with_retry), 
            timeout=30.0  # 30 second timeout for wallet operations
        )
        
        # ARCHITECT FIX: Ensure strict boolean return type
        if not isinstance(result, bool):
            logger.error(f"‚ùå WALLET_CREDIT_TYPE_ERROR: Function returned {type(result)} instead of bool: {result}")
            return False
        return result
        
    except asyncio.TimeoutError:
        logger.error(f"‚ùå WALLET_CREDIT_TIMEOUT: Operation timed out after 30s for user_id {user_id} | txid: {txid[:16]}...")
        return False
        
    except asyncio.CancelledError:
        logger.warning(f"‚ö†Ô∏è WALLET_CREDIT_CANCELLED: Operation cancelled for user_id {user_id} | txid: {txid[:16]}...")
        return False
        
    except Exception as async_error:
        logger.error(f"‚ùå WALLET_CREDIT_ASYNC_ERROR: Threading error for user_id {user_id} | Error Type: {type(async_error).__name__} | Error: {async_error}")
        return False

async def get_user_wallet_transactions(user_id: int, limit: int = 10) -> List[Dict]:
    """Get user's recent wallet transactions"""
    try:
        return await execute_query(
            "SELECT * FROM wallet_transactions WHERE user_id = %s ORDER BY created_at DESC LIMIT %s",
            (user_id, limit)
        )
    except Exception as e:
        logger.error(f"Error getting wallet transactions: {e}")
        return []

async def reserve_wallet_balance(user_id: int, amount: float, description: str = '') -> Optional[int]:
    """Reserve amount from wallet (hold transaction) with atomic protection - returns transaction ID"""
    import psycopg2
    
    def _atomic_reserve() -> Optional[int]:
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # SECURITY: Row-level lock to prevent race conditions
                cursor.execute(
                    "SELECT id, wallet_balance FROM users WHERE id = %s FOR UPDATE",
                    (user_id,)
                )
                user_row = cast(Optional[RealDictRow], cursor.fetchone())
                if not user_row:
                    logger.error(f"User {user_id} not found for wallet reservation")
                    conn.rollback()
                    return None
                
                current_balance = float(user_row['wallet_balance'] or 0.00)
                
                # Validate amount bounds
                if amount <= 0:
                    logger.error(f"üö´ RESERVATION VALIDATION: Invalid amount for user {user_id}: {amount}")
                    conn.rollback()
                    return None
                
                if amount > 999999.99:
                    logger.error(f"üö´ RESERVATION VALIDATION: Amount too large for user {user_id}: {amount}")
                    conn.rollback()
                    return None
                
                # CRITICAL: Check sufficient balance
                if current_balance < amount:
                    logger.warning(f"üö´ RESERVATION PROTECTION: User {user_id} insufficient balance: {current_balance} < {amount}")
                    conn.rollback()
                    return None
                
                new_balance = current_balance - amount
                
                # Double-check negative balance protection
                if new_balance < 0:
                    logger.error(f"üö´ ATOMIC PROTECTION: Would create negative balance for user {user_id}: {new_balance}")
                    conn.rollback()
                    return None
                
                # Create hold transaction first
                cursor.execute(
                    "INSERT INTO wallet_transactions (user_id, transaction_type, amount, currency, status, description) VALUES (%s, %s, %s, %s, %s, %s) RETURNING id",
                    (user_id, 'hold', -amount, 'USD', 'pending', f"Hold: {description}")
                )
                transaction_result = cast(Optional[RealDictRow], cursor.fetchone())
                transaction_id = transaction_result['id'] if transaction_result else None
                
                if not transaction_id:
                    logger.error(f"Failed to create hold transaction for user {user_id}")
                    conn.rollback()
                    return None
                
                # Update user balance atomically
                cursor.execute(
                    "UPDATE users SET wallet_balance = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                    (new_balance, user_id)
                )
                
                # Commit atomic transaction
                conn.commit()
                # Enhanced balance tracking with Old ‚Üí New format for comprehensive audit trail
                logger.info(f"‚úÖ RESERVATION SUCCESS: ${amount:.2f} reserved for user {user_id} | Old: ${current_balance:.2f} ‚Üí New: ${new_balance:.2f} | Transaction ID: {transaction_id} | Description: {description}")
                return transaction_id
                
        except psycopg2.IntegrityError as e:
            if conn:
                conn.rollback()
            if "wallet_balance_non_negative" in str(e):
                logger.error(f"üö´ DATABASE CONSTRAINT: Negative balance prevented by DB constraint for user {user_id}")
            else:
                logger.error(f"Database integrity error in wallet reservation: {e}")
            return None
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Error in atomic wallet reservation: {e}")
            return None
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_reserve)

async def finalize_wallet_reservation(transaction_id: int, success: bool = True) -> bool:
    """Finalize a wallet hold transaction with atomic protection"""
    import psycopg2
    
    def _atomic_finalize() -> bool:
        conn = None
        try:
            conn = get_connection()
            # CRITICAL: Disable autocommit for atomic transaction
            conn.autocommit = False
            
            with conn.cursor() as cursor:
                # SECURITY: Lock the transaction row to prevent double-processing
                cursor.execute(
                    "SELECT id, user_id, amount, status, transaction_type FROM wallet_transactions WHERE id = %s FOR UPDATE",
                    (transaction_id,)
                )
                transaction_row = cast(Optional[RealDictRow], cursor.fetchone())
                if not transaction_row:
                    logger.error(f"Transaction {transaction_id} not found for finalization")
                    conn.rollback()
                    return False
                
                # Validate transaction state
                if transaction_row['status'] != 'pending':
                    logger.warning(f"üö´ FINALIZATION PROTECTION: Transaction {transaction_id} already finalized with status: {transaction_row['status']}")
                    conn.rollback()
                    return False
                
                if transaction_row['transaction_type'] != 'hold':
                    logger.error(f"üö´ FINALIZATION VALIDATION: Transaction {transaction_id} is not a hold transaction: {transaction_row['transaction_type']}")
                    conn.rollback()
                    return False
                
                user_id = transaction_row['user_id']
                hold_amount = abs(float(transaction_row['amount']))
                
                if success:
                    # Mark hold as completed (debit)
                    cursor.execute(
                        "UPDATE wallet_transactions SET status = 'completed', transaction_type = 'debit', updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (transaction_id,)
                    )
                    logger.info(f"‚úÖ HOLD FINALIZED: Transaction {transaction_id} completed as debit for user {user_id}")
                else:
                    # Refund the hold amount atomically
                    cursor.execute(
                        "SELECT id, wallet_balance FROM users WHERE id = %s FOR UPDATE",
                        (user_id,)
                    )
                    user_row = cast(Optional[RealDictRow], cursor.fetchone())
                    if not user_row:
                        logger.error(f"User {user_id} not found for hold refund")
                        conn.rollback()
                        return False
                    
                    current_balance = float(user_row['wallet_balance'] or 0.00)
                    new_balance = current_balance + hold_amount
                    
                    # Validate refund bounds
                    if new_balance > 999999.99:
                        logger.error(f"üö´ REFUND VALIDATION: Refund would exceed balance limit for user {user_id}: {new_balance}")
                        conn.rollback()
                        return False
                    
                    # Refund to user balance
                    cursor.execute(
                        "UPDATE users SET wallet_balance = %s, updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (new_balance, user_id)
                    )
                    
                    # Create refund transaction record
                    cursor.execute(
                        "INSERT INTO wallet_transactions (user_id, transaction_type, amount, currency, status, description) VALUES (%s, %s, %s, %s, %s, %s)",
                        (user_id, 'credit', hold_amount, 'USD', 'completed', "Refund from cancelled order")
                    )
                    
                    # Mark hold as cancelled
                    cursor.execute(
                        "UPDATE wallet_transactions SET status = 'cancelled', updated_at = CURRENT_TIMESTAMP WHERE id = %s",
                        (transaction_id,)
                    )
                    
                    logger.info(f"‚úÖ HOLD REFUNDED: Transaction {transaction_id} cancelled, ${hold_amount} refunded to user {user_id}")
                
                # Commit atomic transaction
                conn.commit()
                return True
                
        except psycopg2.IntegrityError as e:
            if conn:
                conn.rollback()
            logger.error(f"Database integrity error in wallet finalization: {e}")
            return False
        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"Error in atomic wallet finalization: {e}")
            return False
        finally:
            if conn:
                return_connection(conn)
    
    return await asyncio.to_thread(_atomic_finalize)

# ====================================================================
# DNS OPTIMISTIC CONCURRENCY CONTROL FUNCTIONS
# ====================================================================

async def get_dns_record_version(record_id: str) -> Optional[Dict[str, Any]]:
    """Get DNS record version data for optimistic concurrency control"""
    def _get_version():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    """SELECT record_id, zone_id, record_type, last_modified_at, 
                              version_etag, content_hash, record_data
                       FROM dns_record_versions WHERE record_id = %s""",
                    (record_id,)
                )
                result = cursor.fetchone()
                return dict(result) if result else None
        except Exception as e:
            logger.error(f"Failed to get DNS record version for {record_id}: {e}")
            return None
        finally:
            return_connection(conn)
    
    return await run_db(_get_version)

async def update_dns_record_version(record_id: str, zone_id: str, record_type: str, 
                                   version_etag: str, content_hash: str, 
                                   record_data: Dict[str, Any], 
                                   expected_etag: Optional[str] = None) -> Dict[str, Any]:
    """
    Update DNS record version with proper Compare-And-Set (CAS) semantics for optimistic concurrency control
    
    Returns:
        Dict with 'success' (bool), 'conflict' (bool), and optional 'current_etag' (str)
    """
    def _update_version():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                if expected_etag is not None:
                    # EXISTING RECORD: Use CAS semantics with UPDATE ... WHERE version_etag = expected
                    logger.debug(f"üîí CAS UPDATE: {record_id} expected:{expected_etag[:8]}... -> new:{version_etag[:8]}...")
                    
                    cursor.execute(
                        """UPDATE dns_record_versions 
                           SET zone_id = %s, record_type = %s, version_etag = %s, 
                               content_hash = %s, record_data = %s, last_modified_at = CURRENT_TIMESTAMP
                           WHERE record_id = %s AND version_etag = %s""",
                        (zone_id, record_type, version_etag, content_hash, 
                         json.dumps(record_data), record_id, expected_etag)
                    )
                    
                    if cursor.rowcount == 0:
                        # CAS CONFLICT: No rows updated - either wrong etag or record deleted
                        logger.warning(f"üö´ CAS CONFLICT: {record_id} expected:{expected_etag[:8]}... (conflict detected)")
                        
                        # Get current etag for conflict resolution
                        cursor.execute(
                            "SELECT version_etag FROM dns_record_versions WHERE record_id = %s",
                            (record_id,)
                        )
                        current_row = cursor.fetchone()
                        current_etag = dict(current_row)['version_etag'] if current_row else None
                        
                        return {
                            'success': False,
                            'conflict': True,
                            'current_etag': current_etag,
                            'expected_etag': expected_etag
                        }
                    
                    logger.debug(f"‚úÖ CAS SUCCESS: {record_id} updated to etag:{version_etag[:8]}...")
                    return {'success': True, 'conflict': False}
                    
                else:
                    # NEW RECORD: Insert if not exists (first writer wins)
                    logger.debug(f"üÜï INSERT NEW: {record_id} etag:{version_etag[:8]}...")
                    
                    cursor.execute(
                        """INSERT INTO dns_record_versions 
                           (record_id, zone_id, record_type, version_etag, content_hash, 
                            record_data, last_modified_at, created_at)
                           VALUES (%s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
                           ON CONFLICT (record_id) DO NOTHING""",
                        (record_id, zone_id, record_type, version_etag, content_hash, 
                         json.dumps(record_data))
                    )
                    
                    if cursor.rowcount == 0:
                        # RACE CONDITION: Another session inserted first
                        logger.warning(f"üîÑ INSERT RACE: {record_id} - another session created record first")
                        
                        # Get the winning etag for conflict resolution
                        cursor.execute(
                            "SELECT version_etag FROM dns_record_versions WHERE record_id = %s",
                            (record_id,)
                        )
                        current_row = cursor.fetchone()
                        current_etag = dict(current_row)['version_etag'] if current_row else None
                        
                        return {
                            'success': False,
                            'conflict': True,
                            'current_etag': current_etag,
                            'expected_etag': expected_etag
                        }
                    
                    logger.debug(f"‚úÖ INSERT SUCCESS: {record_id} created with etag:{version_etag[:8]}...")
                    return {'success': True, 'conflict': False}
                    
        except Exception as e:
            logger.error(f"Failed to update DNS record version for {record_id}: {e}")
            return {'success': False, 'conflict': False, 'error': str(e)}
        finally:
            return_connection(conn)
    
    return await run_db(_update_version)

async def check_dns_record_conflict(record_id: str, expected_etag: str) -> Tuple[bool, Optional[str]]:
    """Check if DNS record has version conflict (optimistic concurrency control)"""
    def _check_conflict():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    "SELECT version_etag FROM dns_record_versions WHERE record_id = %s",
                    (record_id,)
                )
                result = cursor.fetchone()
                
                if not result:
                    # No version tracked yet - no conflict
                    return False, None
                
                current_etag = dict(result)['version_etag']
                has_conflict = current_etag != expected_etag
                
                if has_conflict:
                    logger.warning(f"üîÑ DNS version conflict detected: record {record_id}, "
                                 f"expected {expected_etag[:8]}..., current {current_etag[:8]}...")
                
                return has_conflict, current_etag
        except Exception as e:
            logger.error(f"Failed to check DNS record conflict for {record_id}: {e}")
            return False, None
        finally:
            return_connection(conn)
    
    return await run_db(_check_conflict)

async def check_zone_creation_lock(domain_id: int) -> bool:
    """Check if zone creation is already in progress for domain (row-level lock)"""
    def _check_lock():
        conn = get_connection()
        try:
            conn.autocommit = False  # Need transaction for row lock
            with conn.cursor() as cursor:
                # Check if cloudflare zone already exists with row lock
                cursor.execute(
                    "SELECT id FROM cloudflare_zones WHERE domain_id = %s FOR UPDATE NOWAIT",
                    (domain_id,)
                )
                result = cursor.fetchone()
                conn.rollback()  # Release lock
                return result is not None
        except psycopg2.errors.LockNotAvailable:
            logger.warning(f"Zone creation lock detected for domain {domain_id}")
            if conn:
                conn.rollback()
            return True  # Lock exists - zone creation in progress
        except Exception as e:
            logger.error(f"Failed to check zone creation lock for domain {domain_id}: {e}")
            if conn:
                conn.rollback()
            return False
        finally:
            if conn:
                conn.autocommit = True
                return_connection(conn)
    
    return await run_db(_check_lock)

async def create_zone_with_lock(domain_id: int, domain_name: str, cf_zone_id: str, 
                               nameservers: List[str], status: str) -> bool:
    """Create Cloudflare zone with atomic domain lock to prevent conflicts"""
    def _create_with_lock():
        conn = get_connection()
        try:
            conn.autocommit = False  # Need transaction for atomic operation
            
            with conn.cursor() as cursor:
                # 1. Lock the domain row to serialize zone creation
                cursor.execute(
                    "SELECT id, domain_name FROM domains WHERE id = %s FOR UPDATE",
                    (domain_id,)
                )
                domain_result = cursor.fetchone()
                if not domain_result:
                    logger.error(f"Domain {domain_id} not found for zone creation")
                    conn.rollback()
                    return False
                
                # 2. Check if zone already exists (within transaction)
                cursor.execute(
                    "SELECT id FROM cloudflare_zones WHERE domain_id = %s",
                    (domain_id,)
                )
                existing_zone = cursor.fetchone()
                if existing_zone:
                    logger.info(f"Zone already exists for domain {domain_id}")
                    conn.rollback()
                    return True  # Not an error - zone exists
                
                # 3. Create the zone atomically
                cursor.execute(
                    """INSERT INTO cloudflare_zones 
                       (domain_id, domain_name, cf_zone_id, nameservers, status, created_at, updated_at)
                       VALUES (%s, %s, %s, %s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)""",
                    (domain_id, domain_name, cf_zone_id, nameservers, status)
                )
                
                conn.commit()
                logger.info(f"‚úÖ Zone created atomically: {domain_name} -> {cf_zone_id}")
                return True
                
        except psycopg2.errors.UniqueViolation:
            logger.info(f"Zone already exists (unique constraint): domain {domain_id}")
            if conn:
                conn.rollback()
            return True  # Not an error - unique constraint handled it
        except Exception as e:
            logger.error(f"Failed to create zone with lock for domain {domain_id}: {e}")
            if conn:
                conn.rollback()
            return False
        finally:
            if conn:
                conn.autocommit = True
                return_connection(conn)
    
    return await run_db(_create_with_lock)

async def get_zone_by_domain_id(domain_id: int) -> Optional[Dict[str, Any]]:
    """Get Cloudflare zone by domain ID for conflict checking"""
    def _get_zone():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    """SELECT cz.id, cz.domain_id, cz.domain_name, cz.cf_zone_id, 
                              cz.nameservers, cz.status, cz.created_at, cz.updated_at
                       FROM cloudflare_zones cz WHERE cz.domain_id = %s""",
                    (domain_id,)
                )
                result = cursor.fetchone()
                return dict(result) if result else None
        except Exception as e:
            logger.error(f"Failed to get zone by domain ID {domain_id}: {e}")
            return None
        finally:
            return_connection(conn)
    
    return await run_db(_get_zone)

async def cleanup_old_dns_versions(older_than_hours: int = 24) -> int:
    """Clean up old DNS record versions to prevent table growth"""
    def _cleanup():
        conn = get_connection()
        try:
            with conn.cursor() as cursor:
                cursor.execute(
                    """DELETE FROM dns_record_versions 
                       WHERE created_at < CURRENT_TIMESTAMP - INTERVAL '%s hours'""",
                    (older_than_hours,)
                )
                deleted_count = cursor.rowcount
                logger.info(f"üóëÔ∏è Cleaned up {deleted_count} old DNS record versions")
                return deleted_count
        except Exception as e:
            logger.error(f"Failed to cleanup old DNS versions: {e}")
            return 0
        finally:
            return_connection(conn)
    
    return await run_db(_cleanup)